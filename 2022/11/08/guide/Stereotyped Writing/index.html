

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/bg/favicon.ico">
  <link rel="icon" href="/img/bg/favicon.ico">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="huan">
  <meta name="keywords" content="">
  
    <meta name="description" content="Java基础Q：StringBuilder和StringBuffer的区别 A：StringBuilder线程安全，效率高，toString实现不同，StringBuilder每次需要复制一次字符数组，再构造一个字符串，StringBuffer每次会直接使用缓存区的toStringCache值来构造一个字符串 Q： Object类有哪些方法? （1）clone方法 保护方法，实现对象的浅复制，只有">
<meta property="og:type" content="article">
<meta property="og:title" content="实习准备">
<meta property="og:url" content="http://example.com/2022/11/08/guide/Stereotyped%20Writing/index.html">
<meta property="og:site_name" content="Huan&#39;s Blog">
<meta property="og:description" content="Java基础Q：StringBuilder和StringBuffer的区别 A：StringBuilder线程安全，效率高，toString实现不同，StringBuilder每次需要复制一次字符数组，再构造一个字符串，StringBuffer每次会直接使用缓存区的toStringCache值来构造一个字符串 Q： Object类有哪些方法? （1）clone方法 保护方法，实现对象的浅复制，只有">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/ab0b44f557f8b5bc7acb3a53d43ebfcb.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/a3b1f6235cf0587115b21312fe60289c.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/4d2dc376b5fd68dae70d9284ae82b73a.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/c5fb0a602d4caaca37ff0357f05b0abf.png">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5/lru%E5%AD%97%E6%AE%B5.png">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5/%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5.jpg">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/86b0046c2622b2c4bda697f9bc0f5b28.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/acb5f4e7ef24a524a53c39eb016f63d4.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/b7031182f770a7a5b3c82eaf749f53b0.png">
<meta property="og:image" content="https://ask.qcloudimg.com/http-save/yehe-4474523/3ac0cf1dcd3100b2b96c55bf4e827adf.png?imageView2/2/w/1620">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/39.jpg">
<meta property="og:image" content="https://pic.leetcode-cn.com/1658848039-ISJPNM-Untitled%201.png">
<meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzMwLmpwZw?x-oss-process=image/format,png">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/8.jpg">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/25-HTTP2.png">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/27-HTTP3.png">
<meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzEwLmpwZw?x-oss-process=image/format,png">
<meta property="og:image" content="http://s2.51cto.com/wyfs02/M02/59/16/wKioL1THNfahGAkDAAFu--59S3M173.jpg">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D.png">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/34.jpg">
<meta property="og:image" content="https://blog.reginvolver.cn/wp-content/uploads/2022/10/image-1666948779530.png">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/35.jpg">
<meta property="og:image" content="https://blog.reginvolver.cn/wp-content/uploads/2022/10/image-1666948484336.png">
<meta property="og:image" content="https://blog.reginvolver.cn/wp-content/uploads/2022/10/image-1666948518233.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200527233246458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xMODQ1ODc2NDI1,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200527233345809.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xMODQ1ODc2NDI1,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/%E7%B4%A2%E5%BC%95/%E7%B4%A2%E5%BC%95%E5%88%86%E7%B1%BB.drawio.png">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/readview%E7%BB%93%E6%9E%84.drawio.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/1e37f6994ef44714aba03b8046b1ace2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/c296c1889f0101d335699311b4ef20a8.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/f380ef357d065498d8d54ad07f145e09.png">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0">
<meta property="og:image" content="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0">
<meta property="og:image" content="http://keithlan.github.io/image/mysql_innodb_arch/commit_4.png">
<meta property="og:image" content="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQlIgynyFHL9VBRpbSanADPgV0cUVI9DBn1VSYsbibiamRzWzsRqukRRag/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">
<meta property="og:image" content="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQPxyPYiaDmGYPCWtQcCjILVVBFYcdegBSRGly002A7wRYqZ355MBdM0w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">
<meta property="article:published_time" content="2022-11-08T12:07:00.000Z">
<meta property="article:modified_time" content="2022-12-06T07:55:57.464Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="实习">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/img_convert/ab0b44f557f8b5bc7acb3a53d43ebfcb.png">
  
  
  
  <title>实习准备 - Huan&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Huan</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/bg/hero.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="实习准备"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-11-08 20:07" pubdate>
          November 8, 2022 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          51k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          426 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">实习准备</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="Java基础"><a href="#Java基础" class="headerlink" title="Java基础"></a>Java基础</h1><p>Q：StringBuilder和StringBuffer的区别</p>
<p>A：StringBuilder线程安全，效率高，toString实现不同，StringBuilder每次需要复制一次字符数组，再构造一个字符串，StringBuffer每次会直接使用缓存区的toStringCache值来构造一个字符串</p>
<p>Q： Object类有哪些方法?</p>
<p><strong>（1）clone方法</strong></p>
<p>保护方法，实现对象的浅复制，只有实现了Cloneable接口才可以调用该方法，否则抛出CloneNotSupportedException异常。</p>
<p><strong>（2）getClass方法</strong></p>
<p>final方法，获得运行时类型。</p>
<p><strong>（3）toString方法</strong></p>
<p>该方法用得比较多，一般子类都有覆盖。</p>
<p><strong>（4）finalize方法</strong></p>
<p>该方法用于释放资源。因为无法确定该方法什么时候被调用，很少使用。</p>
<p><strong>（5）equals方法</strong></p>
<p>该方法是非常重要的一个方法。一般equals和==是不一样的，但是在Object中两者是一样的。子类一般都要重写这个方法。</p>
<p><strong>（6）hashCode方法</strong></p>
<p>该方法用于哈希查找，重写了equals方法一般都要重写hashCode方法。这个方法在一些具有哈希功能的Collection中用到。</p>
<p>一般必须满足obj1.equals(obj2)==true。可以推出obj1.hash- Code()==obj2.hashCode()，但是hashCode相等不一定就满足equals。不过为了提高效率，应该尽量使上面两个条件接近等价。</p>
<p><strong>（7）wait方法</strong></p>
<p>wait方法就是使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait()方法一直等待，直到获得锁或者被中断。wait(long timeout)设定一个超时间隔，如果在规定时间内没有获得锁就返回。</p>
<p>调用该方法后当前线程进入睡眠状态，直到以下事件发生。</p>
<p>（1）其他线程调用了该对象的notify方法。</p>
<p>（2）其他线程调用了该对象的notifyAll方法。</p>
<p>（3）其他线程调用了interrupt中断该线程。</p>
<p>（4）时间间隔到了。</p>
<p>此时该线程就可以被调度了，如果是被中断的话就抛出一个InterruptedException异常。</p>
<p><strong>（8）notify方法</strong></p>
<p>该方法唤醒在该对象上等待的某个线程。</p>
<p><strong>（9）notifyAll方法</strong></p>
<p>该方法唤醒在该对象上等待的所有线程。</p>
<p>Q： 什么情况下用+运算符进行字符串连接比调用StringBuffer/StringBuilder对象的append方法连接字符串性能更好？</p>
<p>A：对于字面量字符的连接，+更好，大部分情况，StringBuilder的性能更好</p>
<p>Q：<strong>hashmap的原理 能说说hashmap的扩容操作吗？扩容是new一个新的map还是在原来的基础上增加内存？</strong></p>
<ul>
<li>HashMap主干是通过类型为Entry的数组实现的(Entry&lt;K,V&gt;)，在JDK1.8之前由Entry数组和链表组成，在JDK1.8及之后由Entry数组和红黑树组成。 </li>
<li>HashMap内部有几个重要的变量字段：transient用来记录实际存储的键值对的个数。threshold表示扩容阈值，超过该值会触发扩容，计算公式为最大容量capacity * 负载因子loadFactory，默认为12。loadFactory表示负载因子，默认为0.75。 </li>
<li>HashMap在扩容时会调用resize方法，该方***在addEntry方法中调用，也就是说在每次添加键值对的时候会进行扩容判断，具体的判断条件是当前存储的键值对(包括现在要添加的键值对)数量超过threshold的时候会触发扩容，扩容后的Entry数组长度为之前的2倍。 </li>
<li>resize方法内部首先会判断若Entry数组已经扩到了最大值，则提高阈值threshold，返回。否则，则新建一个长度为之前2倍的Entry数组，将原来数组的数据转移到新数组中，最后重新计算阈值threshold。所以说扩容是新建了一个Entry数组。</li>
</ul>
<p>Q：<strong>说说classload（启动类加载器、扩展类加载器、应用类加载器） 能说说双亲委派模型吗？</strong></p>
<p>Java的ClassLoader共分三种：第一种启动类加载器Bootstrap ClassLoader，用于加载Java核心类库，底层为native实现。第二种扩展类加载器Extension ClassLoader，用于加载\lib\ext目录下的类及被java.ext.dirs系统变量指定的类库。第三种应用类加载器Applicaiton ClassLoader，用于加载ClassPath所有指定的类库。还有一种是用户自定义的类加载器。这四类的级别从高到低依次为：Bootstrap ClassLoader、Extension ClassLoader、Applicaiton ClassLoader、用户自定义ClassLoader。<br>双亲委派模型的原理是当一个类加载器收到类加载请求时，首先不会尝试加载，而是请求委派给父类加载器加载，经过递归委派，最后会委派到Bootstrap ClassLoader。当父类无法完成加载请求时，则交给下一级子类来处理加载，若都无法完成加载，最会交给一开始的类加载器进行处理。子类加载器与父类加载器不是以继承的方式实现，而是通过组合的方式复用父类的代码。</p>
<p>Q：<strong>什么是 AOP？</strong></p>
<p>在软件开发过程中，跨越应用程序多个点的功能称为交叉问题。这些交叉问题与应用程序的主要业务逻辑不同。因此，将这些横切关注与业务逻辑分开是面向方</p>
<p>面编程（AOP）的地方。</p>
<p>Q：AOP的实现</p>
<p>A：静态代理和动态代理</p>
<p>Q：<strong>什么是 Spring IOC 容器？</strong></p>
<p>A：Spring 框架的核心是 Spring 容器。容器创建对象，将它们装配在一起，配置它们并管理它们的完整生命周期。Spring 容器使用依赖注入来管理组成应用程序的组件。容器通过读取提供的配置元数据来接收对象进行实例化，配置和组装的指令。该元数据可以通过 XML，Java 注解或 Java 代码提供。</p>
<p>Q：<strong>什么是依赖注入？</strong></p>
<p>A：在依赖注入中，您不必创建对象，但必须描述如何创建它们。您不是直接在代码中将组件和服务连接在一起，而是描述配置文件中哪些组件需要哪些服务。由 IoC容器将它们装配在一起</p>
<p>Q：HashMap扩容为什么必须2的幂次方</p>
<p>A： 达到散列均匀，为了提⾼ HashMap 集合的存取效率，</p>
<p>Q：hashmap计算index的方式</p>
<p>A：求容器下标值的方法，有两步，首先通过key值计算hash，然后用hash计算下标</p>
<h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><p>Q：说说 docker 的应用场景？对应的优缺点？</p>
<p>A：应用在web应用的自动打包和发布、降低运维的成本</p>
<p>优点：1、简化了配置，将环境和代码打包成镜像能运行在各种配置不一的平台。2、提供了开发到上线的一致环境。3、容易与容器是隔离的，能在一台机器上运行不同的应用。4、部署快速，doker创建了一个容器，不需要启动一个操作系统。5、迁移方便</p>
<p>缺点：1、必须在64为机器上运行。2、对linux内核有一定的限制</p>
<h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><p>Q：什么是redis</p>
<p>A：Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此<strong>读写速度非常快</strong>，redis提供了字符串，散列，列表，集合，拍续集和等结构供我们开发者使用。</p>
<p>Q：redis中的String怎么实现</p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/redis/data_struct/data_struct.html#sds-%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1">https://xiaolincoding.com/redis/data_struct/data_struct.html#sds-%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/AmyZheng_/article/details/108788468">https://blog.csdn.net/AmyZheng_/article/details/108788468</a></p>
<p>Q：redis zSet实现限流</p>
<p>A：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/745bb2106537">https://www.jianshu.com/p/745bb2106537</a></p>
<h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><p>redis使用自己的简单动态字符串的抽象类型实现。redis中，默认以SDS作为自己的字符串表示。只有在一些字符串不可能出现变化的地方使用C字符串</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk">struct sdshdr &#123;    <br>  <span class="hljs-regexp">//</span> 用于记录buf数组中使用的字节的数目<br>  <span class="hljs-regexp">//</span> 和SDS存储的字符串的长度相等  <br>	int len;    <br>  <span class="hljs-regexp">//</span> 用于记录buf数组中没有使用的字节的数目   <br>	int free;    <br>  <span class="hljs-regexp">//</span> 字节数组，用于储存字符串<br>	char buf[];   <span class="hljs-regexp">//</span>buf的大小等于len+free+<span class="hljs-number">1</span>，其中多余的<span class="hljs-number">1</span>个字节是用来存储’\<span class="hljs-number">0</span>’的。<br>&#125;;<br></code></pre></td></tr></table></figure>

<p>好处：1、常数复杂度获取字符串长度。2、杜绝缓冲区溢出。3、二进制安全（不是空字符判断结束）。4、减少修改字符串时带来的内存重分配次数。5、兼容c字符串的函数</p>
<p>redis5.0 — SDS结构</p>
<blockquote>
<p>结构中的每个成员变量分别介绍下：</p>
<ul>
<li><strong>len，记录了字符串长度</strong>。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。</li>
<li><strong>alloc，分配给字符数组的空间长度</strong>。这样在修改字符串的时候，可以通过 <code>alloc - len</code> 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。</li>
<li><strong>flags，用来表示不同类型的 SDS</strong>。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。</li>
<li><strong>buf[]，字符数组，用来保存实际数据</strong>。不仅可以保存字符串，也可以保存二进制数据。</li>
</ul>
</blockquote>
<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>Redis中的列表在3.2之前的版本是使用<code>ziplist</code>和<code>linkedlist</code>进行实现的。在3.2之后的版本就是引入了<code>quicklist</code></p>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs objectivec"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> list &#123;<br>    <span class="hljs-comment">//链表头节点</span><br>    listNode *head;<br>    <span class="hljs-comment">//链表尾节点</span><br>    listNode *tail;<br>    <span class="hljs-comment">//节点值复制函数</span><br>    <span class="hljs-type">void</span> *(*dup)(<span class="hljs-type">void</span> *ptr);<br>    <span class="hljs-comment">//节点值释放函数</span><br>    <span class="hljs-type">void</span> (*free)(<span class="hljs-type">void</span> *ptr);<br>    <span class="hljs-comment">//节点值比较函数</span><br>    <span class="hljs-type">int</span> (*match)(<span class="hljs-type">void</span> *ptr, <span class="hljs-type">void</span> *key);<br>    <span class="hljs-comment">//链表节点数量</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> len;<br>&#125; list;<br></code></pre></td></tr></table></figure>

<p>Redis 的链表实现优点如下：</p>
<p>1、获取某个节点的前置和后置节点的时间复杂度只需要O(1) </p>
<p>2、**获取链表的表头节点和表尾节点的时间复杂度只需O(1)**；</p>
<p>3、获取链表中的节点数的时间复杂度只需O(1)；</p>
<p>4、listNode 链表节使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此<strong>链表节点可以保存各种不同类型的值</strong></p>
<p>缺点：</p>
<p>1、链表每个节点之间的内存都是不连续的，意味着<strong>无法很好利用 CPU 缓存</strong>。</p>
<p>2、还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，<strong>内存开销较大</strong></p>
<p>注意：因此，Redis 对象（List 对象、Hash 对象、Zset 对象）包含的元素数量较少，或者元素值不大的情况才会使用压缩列表作为底层数据结构。</p>
<h3 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h3><p>Hash对象的实现方式有两种分别是<code>ziplist、hashtable</code>，其中hashtable的存储方式key是String类型的，value也是以<code>key value</code>的形式进行存储。</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">dictht</span> &#123;<br>    <span class="hljs-comment">//哈希表数组</span><br>    dictEntry **table;<br>    <span class="hljs-comment">//哈希表大小</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> size;  <br>    <span class="hljs-comment">//哈希表大小掩码，用于计算索引值</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> sizemask;<br>    <span class="hljs-comment">//该哈希表已有的节点数量</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> used;<br>&#125; dictht;<br></code></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">dictEntry</span> &#123;<br>    <span class="hljs-comment">//键值对中的键</span><br>    <span class="hljs-type">void</span> *key;<br>  <br>    <span class="hljs-comment">//键值对中的值</span><br>    <span class="hljs-keyword">union</span> &#123;<br>        <span class="hljs-type">void</span> *val;<br>        <span class="hljs-type">uint64_t</span> u64;<br>        <span class="hljs-type">int64_t</span> s64;<br>        <span class="hljs-type">double</span> d;<br>    &#125; v;<br>    <span class="hljs-comment">//指向下一个哈希表节点，形成链表</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">dictEntry</span> *next;<br>&#125; dictEntry;<br></code></pre></td></tr></table></figure>

<p>哈希冲突的解决方案：链式哈希</p>
<h4 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h4><p>哈希表结构设计的这一小节，我给大家介绍了 Redis 使用 dictht 结构体表示哈希表。不过，在实际使用哈希表时，Redis 定义一个 dict 结构体，这个结构体里定义了<strong>两个哈希表（ht[2]）</strong>。</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs fsharp">typedef <span class="hljs-keyword">struct</span> <span class="hljs-keyword">dict</span> &#123;<br>    …<br>    <span class="hljs-comment">//两个Hash表，交替使用，用于rehash操作</span><br>    dictht ht[<span class="hljs-number">2</span>]; <br>    …<br>&#125; <span class="hljs-built_in">dict</span>;<br></code></pre></td></tr></table></figure>

<p>在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间。</p>
<p>随着数据逐步增多，触发了 rehash 操作，这个过程分为三步：</p>
<ul>
<li>给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；</li>
<li>将「哈希表 1 」的数据迁移到「哈希表 2」 中；</li>
<li>迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。</li>
</ul>
<p>渐进式 rehash</p>
<p>为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了<strong>渐进式 rehash</strong>，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。</p>
<p>渐进式 rehash 步骤如下：</p>
<ul>
<li>给「哈希表 2」 分配空间；</li>
<li><strong>在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上</strong>；</li>
<li>随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。</li>
</ul>
<p>这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash 的耗时操作。</p>
<p>在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。</p>
<p>比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。</p>
<p>另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表</p>
<h3 id="整数集合Set"><a href="#整数集合Set" class="headerlink" title="整数集合Set"></a>整数集合Set</h3><p>Set的低层存储结构使用了intset和hashTable实现</p>
<p>Set集合的应用场景可以用来<strong>「去重、抽奖、共同好友、二度好友」</strong>等业务类型</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">typedef</span> struct <span class="hljs-built_in">int</span><span class="hljs-keyword">set</span> &#123;<br>    <span class="hljs-comment">//编码方式</span><br>    <span class="hljs-built_in">uint32</span>_t encoding;<br>    <span class="hljs-comment">//集合包含的元素数量</span><br>    <span class="hljs-built_in">uint32</span>_t length;<br>    <span class="hljs-comment">//保存元素的数组</span><br>    <span class="hljs-built_in">int8</span>_t contents[];<br>&#125; <span class="hljs-built_in">int</span><span class="hljs-keyword">set</span>;<br></code></pre></td></tr></table></figure>

<blockquote>
<p>可以看到，保存元素的容器是一个 contents 数组，虽然 contents 被声明为 int8_t 类型的数组，但是实际上 contents 数组并不保存任何 int8_t 类型的元素，contents 数组的真正类型取决于 intset 结构体里的 encoding 属性的值。比如：</p>
<ul>
<li>如果 encoding 属性值为 INTSET_ENC_INT16，那么 contents 就是一个 int16_t 类型的数组，数组中每一个元素的类型都是 int16_t；</li>
<li>如果 encoding 属性值为 INTSET_ENC_INT32，那么 contents 就是一个 int32_t 类型的数组，数组中每一个元素的类型都是 int32_t；</li>
<li>如果 encoding 属性值为 INTSET_ENC_INT64，那么 contents 就是一个 int64_t 类型的数组，数组中每一个元素的类型都是 int64_t；</li>
</ul>
</blockquote>
<p>Q：intset和hashtable编码转换<br>当一个集合满足以下两个条件时，Redis会选择使用intset编码：</p>
<p>1、集合对象保存的所有元素都是整数值。<br>2、集合对象保存的元素数量小于等于512个(这个阈值可以通过配置文件set-max-intset-entries来控制)。<br>一旦集合中的元素不满足上面两个条件，则会选择使用hashtable编码。</p>
<h3 id="Zset"><a href="#Zset" class="headerlink" title="Zset"></a>Zset</h3><p>Redis 只有 Zset 对象的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs fsharp">typedef <span class="hljs-keyword">struct</span> <span class="hljs-keyword">zset</span> &#123;<br>    <span class="hljs-built_in">dict</span> <span class="hljs-operator">*</span><span class="hljs-built_in">dict</span>;<br>    zskiplist <span class="hljs-operator">*</span>zsl;<br>&#125; zset;<br></code></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">zskiplistNode</span> &#123;<br>    <span class="hljs-comment">//Zset 对象的元素值</span><br>    sds ele;<br>    <span class="hljs-comment">//元素权重值</span><br>    <span class="hljs-type">double</span> score;<br>    <span class="hljs-comment">//后向指针</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">zskiplistNode</span> *backward;<br>  <br>    <span class="hljs-comment">//节点的level数组，保存每层上的前向指针和跨度</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">zskiplistLevel</span> &#123;<br>        <span class="hljs-keyword">struct</span> <span class="hljs-title class_">zskiplistNode</span> *forward;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> span;<br>    &#125; level[];<br>&#125; zskiplistNode;<br></code></pre></td></tr></table></figure>



<p>Zset 对象在执行数据插入或是数据更新的过程中，会依次在跳表和哈希表中插入或更新相应的数据，从而保证了跳表和哈希表中记录的信息一致。</p>
<p>Zset 对象能支持范围查询（如 ZRANGEBYSCORE 操作），这是因为它的数据结构设计采用了跳表，而又能以常数复杂度获取元素权重（如 ZSCORE 操作），这是因为它同时采用了哈希表进行索引。</p>
<p>Zset 对象在使用跳表作为数据结构的时候，是使用由「哈希表+跳表」组成的 struct zset，但是我们讨论的时候，都会说跳表是 Zset 对象的底层数据结构，而不会提及哈希表，是因为 struct zset 中的哈希表只是用于以常数复杂度获取元素权重，大部分操作都是跳表实现的。</p>
<p>Q：ziplist和skiplist编码转换</p>
<p>当有序集合对象同时满足以下两个条件时，会使用ziplist编码进行存储：</p>
<p>1、有序集合对象中保存的元素个数小于128个（可以通过配置zset-max-ziplist-entries修改）。<br>2、有序集合对象中保存的所有元素的总长度小于64字节（可以通过配置zset-max-ziplist-value修改）。</p>
<h4 id="跳表多层级的实现"><a href="#跳表多层级的实现" class="headerlink" title="跳表多层级的实现"></a>跳表多层级的实现</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> &#123;</span><br>    <span class="hljs-comment">//Zset 对象的元素值</span><br>    sds ele;<br>    <span class="hljs-comment">//元素权重值</span><br>    <span class="hljs-type">double</span> score;<br>    <span class="hljs-comment">//后向指针</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">backward</span>;</span><br>  <br>    <span class="hljs-comment">//节点的level数组，保存每层上的前向指针和跨度</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistLevel</span> &#123;</span><br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">forward</span>;</span><br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> span;<br>    &#125; level[];<br>&#125; zskiplistNode;<br></code></pre></td></tr></table></figure>

<p><strong>跨度实际上是为了计算这个节点在跳表中的排位</strong>。具体怎么做的呢？因为跳表中的节点都是按序排列的，那么计算某个节点排位的时候，从头节点点到该结点的查询路径上，将沿途访问过的所有层的跨度累加起来，得到的结果就是目标节点在跳表中的排位。</p>
<h4 id="跳表节点查询过程"><a href="#跳表节点查询过程" class="headerlink" title="跳表节点查询过程"></a>跳表节点查询过程</h4><p>查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件：</p>
<ul>
<li>如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。</li>
<li>如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。</li>
</ul>
<p>如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。</p>
<h3 id="ziplist"><a href="#ziplist" class="headerlink" title="ziplist"></a>ziplist</h3><p>压缩列表是 Redis 为了节约内存而开发的，它是<strong>由连续内存块组成的顺序型数据结构</strong>，有点类似于数组。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/ab0b44f557f8b5bc7acb3a53d43ebfcb.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>压缩列表在表头有三个字段：</p>
<ul>
<li><em><strong>zlbytes</strong></em>，记录整个压缩列表占用对内存字节数；</li>
<li><em><strong>zltail</strong></em>，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；</li>
<li><em><strong>zllen</strong></em>，记录压缩列表包含的节点数量；</li>
<li><em><strong>zlend</strong></em>，标记压缩列表的结束点，固定值 0xFF（十进制255）。</li>
</ul>
<p>在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段（zllen）的长度直接定位，复杂度是 O(1)。而<strong>查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/a3b1f6235cf0587115b21312fe60289c.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h4 id="连锁更新问题"><a href="#连锁更新问题" class="headerlink" title="连锁更新问题"></a>连锁更新问题</h4><p><strong>压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降</strong>。</p>
<h4 id="压缩列表的缺陷"><a href="#压缩列表的缺陷" class="headerlink" title="压缩列表的缺陷"></a>压缩列表的缺陷</h4><p>空间扩展操作也就是重新分配内存，因此<strong>连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能</strong>。</p>
<p>所以说，<strong>虽然压缩列表紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，会导致内存重新分配，最糟糕的是会有「连锁更新」的问题</strong>。</p>
<p>因此，<strong>压缩列表只会用于保存的节点数量不多的场景</strong>，只要节点数量足够小，即使发生连锁更新，也是能接受的。</p>
<h3 id="quicklist"><a href="#quicklist" class="headerlink" title="quicklist"></a>quicklist</h3><p>quicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">quicklist</span> &#123;<br>    <span class="hljs-comment">//quicklist的链表头</span><br>    quicklistNode *head;      <span class="hljs-comment">//quicklist的链表头</span><br>    <span class="hljs-comment">//quicklist的链表尾</span><br>    quicklistNode *tail; <br>    <span class="hljs-comment">//所有压缩列表中的总元素个数</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> count;<br>    <span class="hljs-comment">//quicklistNodes的个数</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> len;       <br>    ...<br>&#125; quicklist;<br></code></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">quicklistNode</span> &#123;<br>    <span class="hljs-comment">//前一个quicklistNode</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">quicklistNode</span> *prev;     <span class="hljs-comment">//前一个quicklistNode</span><br>    <span class="hljs-comment">//下一个quicklistNode</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">quicklistNode</span> *next;     <span class="hljs-comment">//后一个quicklistNode</span><br>    <span class="hljs-comment">//quicklistNode指向的压缩列表</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> *zl;              <br>    <span class="hljs-comment">//压缩列表的的字节大小</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> sz;                <br>    <span class="hljs-comment">//压缩列表的元素个数</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> count : <span class="hljs-number">16</span>;        <span class="hljs-comment">//ziplist中的元素个数 </span><br>    ....<br>&#125; quicklistNode;<br></code></pre></td></tr></table></figure>

<p>在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。</p>
<p>quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题</p>
<h3 id="listpack"><a href="#listpack" class="headerlink" title="listpack"></a>listpack</h3><p>listpack 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/4d2dc376b5fd68dae70d9284ae82b73a.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>每个 listpack 节点结构如下：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/c5fb0a602d4caaca37ff0357f05b0abf.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p><strong>listpack 没有压缩列表中记录前一个节点长度的字段，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</strong>。</p>
<h3 id="redis持久化"><a href="#redis持久化" class="headerlink" title="redis持久化"></a>redis持久化</h3><p>Q：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/44196874">redis的持久化方案</a></p>
<p>默认是RDB的方式，rdb是通过快照的方式完成的，当符合一定条件时Redis会自动将内存中的数据进行快照并持久化到硬盘</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">save</span> <span class="hljs-number">900</span> <span class="hljs-number">1</span> ： 表示<span class="hljs-number">15</span>分钟（<span class="hljs-number">900</span>秒钟）内至少<span class="hljs-number">1</span>个键被更改则进行快照。<br><br><span class="hljs-attribute">save</span> <span class="hljs-number">300</span> <span class="hljs-number">10</span> ： 表示<span class="hljs-number">5</span>分钟（<span class="hljs-number">300</span>秒）内至少<span class="hljs-number">10</span>个键被更改则进行快照。<br><br><span class="hljs-attribute">save</span> <span class="hljs-number">60</span> <span class="hljs-number">10000</span> ：表示<span class="hljs-number">1</span>分钟内至少<span class="hljs-number">10000</span>个键被更改则进行快照。<br></code></pre></td></tr></table></figure>

<p>特别说明，redis启动后会读取RDB快照文件，将数据从硬盘载入内存</p>
<p>AOF持久化方式需要手动开启（修改redis.conf中的appendonly参数），开启 AOF 持久化后每执行一条会<strong>更改 Redis 中的数据的命令</strong>，Redis 就会将该命令写入硬盘中的 AOF 文件，这一过程显然<strong>会降低 Redis 的性能</strong>，但大部分情况下这个影响是能够接受的，另外使<strong>用较快的硬盘可以提高 AOF 的性能</strong>（固态硬盘）。</p>
<p>Q：快照的实现原理</p>
<blockquote>
<p>（1）Redis 使用 fork 函数复制一份当前进程的副本(子进程)</p>
<p>（2）父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件。</p>
<p>（3）当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此，一次快照操作完成。</p>
</blockquote>
<p>Q：RDB的优缺点</p>
<blockquote>
<p>优点： RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无需执行任何磁盘 I/O 操作。同时这个也是一个缺点，如果数据集比较大的时候，fork 可以能比较耗时，造成服务器在一段时间内停止处理客户端的请求。</p>
<p>缺点：使用 RDB 方式实现持久化，一旦 Redis 异常退出，就会丢失最后一次快照以后更改的所有数据。这个时候我们就需要根据具体的应用场景，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受范围。如果数据相对来说比较重要，希望将损失降到最小，则可以使用 AOF 方式进行持久化。</p>
</blockquote>
<p>Q：RDB 做快照时会阻塞线程吗？</p>
<blockquote>
<p>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：</p>
<ul>
<li>执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，<strong>会阻塞主线程</strong>；</li>
<li>执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>；</li>
</ul>
</blockquote>
<p>Q：AOF重写原理（优化AOF文件）</p>
<blockquote>
<p>1、Redis可以在AOF文件体积变得过大时，自动地在后台对AOF进行重写，重写后的新AOF文件包含了恢复当前数据集所需地最小命令集合</p>
<p>2、整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。</p>
<p>3、AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。</p>
</blockquote>
<p>Q：AOF文件损坏以后如何恢复</p>
<blockquote>
<p>1、为现有的 AOF 文件创建一个备份。</p>
<p>2、使用 Redis 附带的 <strong>redis-check-aof</strong> 程序，对原来的 AOF 文件进行修复。</p>
<p>redis-check-aof –fix</p>
<p>3、重启 Redis 服务器，等待服务器载入修复后的 AOF 文件，并进行数据恢复。</p>
</blockquote>
<p>Q：如何选择 RDB 和 AOF</p>
<p>A：一般来说为了保证数据的安全性要求非常高，应该同时使用，如果可以接受数分钟内的丢失可只使用RDB持久化。值得注意的是同时使用会优先AOF文件来还原数据</p>
<p>Q：redis求交集并集差集</p>
<blockquote>
<ul>
<li><code>sinter key [key …]</code> 查看一个集合的全部成员，该集合是所有给定集合的交集。</li>
<li><code>sunion key [key …]</code> 查看一个集合的全部成员，该集合是所有给定集合的并集。</li>
<li><code>sdiff key [key …]</code> 查看所有给定 key 与第一个 key 的差集</li>
</ul>
</blockquote>
<h3 id="redis过期删除策略和内存淘汰策略"><a href="#redis过期删除策略和内存淘汰策略" class="headerlink" title="redis过期删除策略和内存淘汰策略"></a>redis过期删除策略和内存淘汰策略</h3><h4 id="过期删除策略"><a href="#过期删除策略" class="headerlink" title="过期删除策略"></a>过期删除策略</h4><p>在说 Redis 过期删除策略之前，先跟大家介绍下，常见的三种过期删除策略：</p>
<ul>
<li>定时删除；</li>
<li>惰性删除；</li>
<li>定期删除；</li>
</ul>
<p>Q：定时删除策略是怎么样的？</p>
<p>A：定时删除策略的做法是，<strong>在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。</strong></p>
<p>定时删除策略的<strong>优点</strong>：</p>
<ul>
<li>可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。</li>
</ul>
<p>定时删除策略的<strong>缺点</strong>：</p>
<ul>
<li>在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。</li>
</ul>
<p>Q：</p>
<p>A：</p>
<p>惰性删除策略的做法是，<strong>不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。</strong></p>
<p>惰性删除策略的<strong>优点</strong>：</p>
<ul>
<li>因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。</li>
</ul>
<p>惰性删除策略的<strong>缺点</strong>：</p>
<ul>
<li>如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。</li>
</ul>
<p>Q：定期删除策略是怎么样的？</p>
<p>A：定期删除策略的做法是，<strong>每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong></p>
<p>定期删除策略的<strong>优点</strong>：</p>
<ul>
<li>通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。</li>
</ul>
<p>定期删除策略的<strong>缺点</strong>：</p>
<ul>
<li>内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。</li>
<li>难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。</li>
</ul>
<p>Q：定期删除的流程</p>
<p>A：</p>
<ol>
<li>从过期字典中随机抽取 20 个 key；</li>
<li>检查这 20 个 key 是否过期，并删除已过期的 key；</li>
<li>如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。</li>
</ol>
<p>可以看到，定期删除是一个循环的流程。</p>
<p>那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。</p>
<h4 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h4><p>前面说的过期删除策略，是删除已过期的 key，而当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。</p>
<p>Q：如何设置 Redis 最大运行内存？</p>
<p>在配置文件 redis.conf 中，可以通过参数 <code>maxmemory &lt;bytes&gt;</code> 来设定最大运行内存，只有在 Redis 的运行内存达到了我们设置的最大运行内存，才会触发内存淘汰策略。 不同位数的操作系统，maxmemory 的默认值是不同的：</p>
<ul>
<li>在 64 位操作系统中，maxmemory 的默认值是 0，表示没有内存大小限制，那么不管用户存放多少数据到 Redis 中，Redis 也不会对可用内存进行检查，直到 Redis 实例因内存不足而崩溃也无作为。</li>
<li>在 32 位操作系统中，maxmemory 的默认值是 3G，因为 32 位的机器最大只支持 4GB 的内存，而系统本身就需要一定的内存资源来支持运行，所以 32 位操作系统限制最大 3 GB 的可用内存是非常合理的，这样可以避免因为内存不足而导致 Redis 实例崩溃。</li>
</ul>
<p>Q：Redis 内存淘汰策略有哪些？</p>
<p>A：Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。</p>
<p><em>1、不进行数据淘汰的策略</em></p>
<p><strong>noeviction</strong>（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，则会触发 OOM，但是如果没用数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作。</p>
<p><em>2、进行数据淘汰的策略</em></p>
<p>针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。</p>
<p>在设置了过期时间的数据中进行淘汰：</p>
<ul>
<li><strong>volatile-random</strong>：随机淘汰设置了过期时间的任意键值；</li>
<li><strong>volatile-ttl</strong>：优先淘汰更早过期的键值。</li>
<li><strong>volatile-lru</strong>（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；</li>
<li><strong>volatile-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；</li>
</ul>
<p>在所有数据范围内进行淘汰：</p>
<ul>
<li><strong>allkeys-random</strong>：随机淘汰任意键值;</li>
<li><strong>allkeys-lru</strong>：淘汰整个键值中最久未使用的键值；</li>
<li><strong>allkeys-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。</li>
</ul>
<p>Q：什么是 LRU 算法？</p>
<p>A：<strong>LRU</strong> 全称是 Least Recently Used 翻译为<strong>最近最少使用</strong>，会选择淘汰最近最少使用的数据。</p>
<p>Q：Redis 是如何实现 LRU 算法的？</p>
<p>A：</p>
<p>传统的 LRU 算法存在两个问题：</p>
<ul>
<li>需要用链表管理所有的缓存数据，这会带来额外的空间开销；</li>
<li>当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。</li>
</ul>
<p>Redis 实现的是一种<strong>近似 LRU 算法</strong>，目的是为了更好的节约内存，它的<strong>实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间</strong>。</p>
<p>当 Redis 进行内存淘汰时，会使用<strong>随机采样的方式来淘汰数据</strong>，它是随机取 5 个值（此值可配置），然后<strong>淘汰最久没有使用的那个</strong>。</p>
<p>Redis 实现的 LRU 算法的优点：</p>
<ul>
<li>不用为所有的数据维护一个大链表，节省了空间占用；</li>
<li>不用在每次数据访问时都移动链表项，提升了缓存的性能；</li>
</ul>
<p>但是 LRU 算法有一个问题，<strong>无法解决缓存污染问题</strong>，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。</p>
<p>Q：Redis 是如何实现 LFU 算法的？</p>
<p>A：LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息。</p>
<p>Redis 对象头中的 lru 字段，在 LRU 算法下和 LFU 算法下使用方式并不相同。</p>
<p><strong>在 LRU 算法中</strong>，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。</p>
<p><strong>在 LFU 算法中</strong>，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5/lru%E5%AD%97%E6%AE%B5.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<ul>
<li>ldt 是用来记录 key 的访问时间戳；</li>
<li>logc 是用来记录 key 的访问频次，它的值越小表示使用频率越低，越容易淘汰，每个新加入的 key 的logc 初始值为 5。</li>
</ul>
<p>所以，Redis 在访问 key 时，对于 logc 是这样变化的：</p>
<ol>
<li>先按照上次访问距离当前的时长，来对 logc 进行衰减；</li>
<li>然后，再按照一定概率增加 logc 的值</li>
</ol>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5/%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<h3 id="redis线程模型"><a href="#redis线程模型" class="headerlink" title="redis线程模型"></a>redis线程模型</h3><p>Q：Redis 是单线程吗？</p>
<p>A：<strong>Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的</strong>，这也是我们常说 Redis 是单线程的原因。</p>
<p>但是，<strong>Redis 程序并不是单线程的</strong>，Redis 在启动的时候，是会<strong>启动后台线程</strong>（BIO）的：</p>
<ul>
<li><strong>Redis 在 2.6 版本</strong>，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；</li>
<li><strong>Redis 在 4.0 版本之后</strong>，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink 命令来异步删除大key。</li>
</ul>
<p>之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。</p>
<p>后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。</p>
<p>Q：<strong>单线程的 Redis 吞吐量可以达到 10W/每秒</strong></p>
<p>Q：Redis 采用单线程为什么还这么快？</p>
<p>A：</p>
<ul>
<li>Redis 的大部分操作<strong>都在内存中完成</strong>，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；</li>
<li>Redis 采用单线程模型可以<strong>避免了多线程之间的竞争</strong>，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li>
<li>Redis 采用了 <strong>I/O 多路复用机制</strong>处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</li>
</ul>
<h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在。</p>
<p>即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。</p>
<p>那问题来了，布隆过滤器是如何工作的呢？接下来，我介绍下。</p>
<p>布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。</p>
<p>布隆过滤器会通过 3 个操作完成标记：</p>
<ul>
<li>第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；</li>
<li>第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。</li>
<li>第三步，将每个哈希值在位图数组的对应位置的值设置为 1；</li>
</ul>
<p>举个例子，假设有一个位图数组长度为 8，哈希函数 3 个的布隆过滤器。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/86b0046c2622b2c4bda697f9bc0f5b28.png" srcset="/img/loading.gif" lazyload alt="图片"></p>
<p>在数据库写入数据 x 后，把数据 x 标记在布隆过滤器时，数据 x 会被 3 个哈希函数分别计算出 3 个哈希值，然后在对这 3 个哈希值对 8 取模，假设取模的结果为 1、4、6，然后把位图数组的第 1、4、6 位置的值设置为 1。<strong>当应用要查询数据 x 是否数据库时，通过布隆过滤器只要查到位图数组的第 1、4、6 位置的值是否全为 1，只要有一个为 0，就认为数据 x 不在数据库中</strong>。</p>
<p>布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时<strong>存在哈希冲突的可能性</strong>，比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上，可能数据库中并不存在数据 y，存在误判的情况。</p>
<p>所以，<strong>查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据</strong>。</p>
<h3 id="redis缓存"><a href="#redis缓存" class="headerlink" title="redis缓存"></a>redis缓存</h3><h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h4><p>Q：如果有大量的key需要设置同一时间过期，一般需要注意什么？</p>
<p>A：如果大量的key过期时间设置的过于集中，到过期的那个时间点，Redis可能会出现短暂的卡顿现象。严重的话会出现缓存雪崩，我们一般需要在时间上加一个随机值，使得过期时间分散一些。 电商首页经常会使用定时任务刷新缓存，可能大量的数据失效时间都十分集中，如果失效时间一样，又刚好在失效的时间点大量用户涌入，就有可能造成缓存雪崩</p>
<p>Q：缓存雪崩的应对方法</p>
<ul>
<li>均匀设置过期时间；</li>
<li>互斥锁；</li>
<li>双 key 策略；</li>
<li>后台更新缓存；</li>
</ul>
<p><em>1. 均匀设置过期时间</em></p>
<p>如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，<strong>给这些数据的过期时间加上一个随机数</strong>，这样就保证数据不会在同一时间过期。</p>
<p><em>2. 互斥锁</em></p>
<p>当业务线程在处理用户请求时，<strong>如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存</strong>（从数据库读取数据，再将数据更新到 Redis 里），当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</p>
<p>实现互斥锁的时候，最好设置<strong>超时时间</strong>，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。</p>
<p><em>3. 双 key 策略</em></p>
<p>我们对缓存数据可以使用两个 key，一个是<strong>主 key，会设置过期时间</strong>，一个是<strong>备 key，不会设置过期</strong>，它们只是 key 不一样，但是 value 值是一样的，相当于给缓存数据做了个副本。</p>
<p>当业务线程访问不到「主 key 」的缓存数据时，就直接返回「备 key 」的缓存数据，然后在更新缓存的时候，<strong>同时更新「主 key 」和「备 key 」的数据。</strong></p>
<p>双 key 策略的好处是，当主 key 过期了，有大量请求获取缓存数据的时候，直接返回备 key 的数据，这样可以快速响应请求。而不用因为 key 失效而导致大量请求被锁阻塞住（采用了互斥锁，仅一个请求来构建缓存），后续再通知后台线程，重新构建主 key 的数据。</p>
<p><em>4. 后台更新缓存</em></p>
<p>业务线程不再负责更新缓存，缓存也不设置有效期，而是<strong>让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新</strong>。</p>
<p>事实上，缓存数据不设置有效期，并不是意味着数据一直能在内存里，因为<strong>当系统内存紧张的时候，有些缓存数据会被“淘汰”</strong>，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。</p>
<p>解决上面的问题的方式有两种。</p>
<p>第一种方式，后台线程不仅负责定时更新缓存，而且也负责<strong>频繁地检测缓存是否有效</strong>，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。</p>
<p>这种方式的检测时间间隔不能太长，太长也导致用户获取的数据是一个空值而不是真正的数据，所以检测的间隔最好是毫秒级的，但是总归是有个间隔时间，用户体验一般。</p>
<p>第二种方式，在业务线程发现缓存数据失效后（缓存数据被淘汰），<strong>通过消息队列发送一条消息通知后台线程更新缓存</strong>，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。</p>
<p>在业务刚上线的时候，我们最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的<strong>缓存预热</strong>，后台更新缓存的机制刚好也适合干这个事情。</p>
<p><strong>针对 Redis 故障宕机而引发的缓存雪崩问题，常见的应对方法：</strong></p>
<p><em>构建 Redis 缓存高可靠集群</em></p>
<h4 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h4><p>我们的业务通常会有几个数据会被频繁地访问，比如秒杀活动，这类被频地访问的数据被称为热点数据。</p>
<p>如果缓存中的<strong>某个热点数据过期</strong>了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是<strong>缓存击穿</strong>的问题。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/acb5f4e7ef24a524a53c39eb016f63d4.png" srcset="/img/loading.gif" lazyload alt="图片"></p>
<p>可以发现缓存击穿跟缓存雪崩很相似，你可以认为缓存击穿是缓存雪崩的一个子集。</p>
<p>应对缓存击穿可以采取前面说到两种方案：</p>
<ul>
<li>互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</li>
<li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；</li>
</ul>
<h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h4><p>当发生缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据，一旦缓存恢复相对应的数据，就可以减轻数据库的压力，而缓存穿透就不一样了。</p>
<p>当用户访问的数据，<strong>既不在缓存中，也不在数据库中</strong>，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是<strong>缓存穿透</strong>的问题。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/b7031182f770a7a5b3c82eaf749f53b0.png" srcset="/img/loading.gif" lazyload alt="图片"></p>
<p>缓存穿透的发生一般有这两种情况：</p>
<ul>
<li>业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；</li>
<li>黑客恶意攻击，故意大量访问某些读取不存在数据的业务；</li>
</ul>
<p>应对缓存穿透的方案，常见的方案有三种。</p>
<ul>
<li>第一种方案，非法请求的限制；</li>
<li>第二种方案，缓存空值或者默认值；</li>
<li>第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；</li>
</ul>
<p>第一种方案，非法请求的限制</p>
<p>当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。</p>
<p>第二种方案，缓存空值或者默认值</p>
<p>当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。</p>
<p><em>第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。</em></p>
<p>我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在。</p>
<p>即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。</p>
<h1 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h1><p>Q：浏览器输入网址发生什么（从dhcp，到dns解析，到http，到tcp，到arp，到nat、到局域网，因特网，我很详细地说了）</p>
<p>A：标答：用户在浏览器中输入URL后， 1.浏览器要做的第一个工作就是解析URL。DNS的流程：首先查浏览器本地存储；如果没有，就查看host文件；如果没有，就请求本地DNS服务器；本地DNS服务器会代理请求根服务器，根服务器返回顶级域名服务器IP；本地DNS服务器会代理请求顶级域名服务器，顶级域名服务器返回权威服务器IP；本地DNS服务器代理请求权威服务器，权威服务器返回URL对应的IP地址；本地DNS服务器将结果返回给浏览器。浏览器开始封装数据包。 2.浏览器要做的第二个工作就是封装数据包。以应用层HTTP协议为例，HTTP报文；接着进入传输层TCP，在TCP头部加上源port和目的port；接着进入网络层IP，在IP头部加上源IP和目的IP；接着进入数据链路层，在数据链路头部加入源MAC和目的MAC；最后进入物理层，数据包被编码为01进行传输。 3.浏览器要做的第三个工作就是发送数据包。浏览器所在的主机会判断目的IP和源IP是否在同一个网段，如果在，会将数据包发送给局域网的交换机进行传输；如果不在，会将数据包发送给局域网的网关进行传输。网关一般是路由器，路由器会查找路由表将数据包传输给下一个网段，经过多个路由器的传输，数据包最终到达目标服务器所在网段，并由网络内的交换机下发给服务器。 4.浏览器要做的第四个工作就是解析页面。服务器接收请求数据包后，会返回页面资源给浏览器。经历过同样的网络传输后，浏览器拿到页面资源并开始解析。首先解析HTML代码生成DOM树，同时获取html文件引用的css文件；再解析css文件生成CSSOM树；解析完DOM树后，会解析获取到的JS文件对DOM树和CSS树进行修改；最后将DOM树和CSS树结合生成render树；接着对render树上的元素进行布局；布局后对元素进行绘制；最后解析图片及视频文件，呈现最终的页面。</p>
<p>浏览器从输入网址到渲染页面主要分为以下几个过程</p>
<ul>
<li><p>URL 输入</p>
<ul>
<li>检查输入的内容是否是一个合法的 URL 链接。</li>
<li>是，则判断输入的 URL 是否完整。如果不完整，浏览器可能会对域进行猜测，补全前缀或者后缀。</li>
<li>否，将输入内容作为搜索条件，使用用户设置的默认搜索引擎来进行搜索。</li>
</ul>
<p>大部分浏览器会从历史记录、书签等地方开始查找我们输入的网址，并给出智能提示</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/product/cns?from=10680">DNS 解析</a></p>
<ul>
<li>在浏览器中输入 hzfe.org 域名，操作系统检查浏览器缓存和本地的 hosts 文件中，是否有这个网址记录，有则从记录里面找到对应的 IP 地址，完成<a target="_blank" rel="noopener" href="https://cloud.tencent.com/product/cns?from=10680">域名解析</a>。</li>
<li>查找本地 DNS 解析器缓存中，是否有这个网址记录，有则从记录里面找到对应的 IP 地址，完成域名解析。</li>
<li>使用 TCP/IP 参数中设置的 DNS 服务器进行查询。如果要查询的域名包含在本地配置区域资源中，则返回解析结果，完成域名解析。</li>
<li>检查本地 DNS 服务器是否缓存该网址记录，有则返回解析结果，完成域名解析。</li>
<li>本地 DNS 服务器发送查询报文至根 DNS 服务器，根 DNS 服务器收到请求后，用顶级域 DNS 服务器地址进行响应。</li>
<li>本地 DNS 服务器发送查询报文至顶级域 DNS 服务器。顶级域 DNS 服务器收到请求后，用权威 DNS 服务器地址进行响应。</li>
<li>本地 DNS 服务器发送查询报文至权威 DNS 服务器，权威 DNS 服务器收到请求后，用 hzfe.org 的 IP 地址进行响应，完成域名解析。</li>
</ul>
<p>查询通常遵循以上流程，从请求主机到本地 DNS 服务器的查询是递归查询，DNS 服务器获取到所需映射的查询过程是迭代查询。</p>
</li>
<li><p>建立 TCP 连接</p>
<ul>
<li>当浏览器获取到服务器的 IP 地址后，浏览器会用一个随机的端口（1024 &lt; 端口 &lt; 65535）向服务器 80 端口发起 TCP 连接请求（注：HTTP 默认约定 80 端口，HTTPS 为 443 端口）。这个连接请求到达服务端后，通过 TCP 三次握手，建立 TCP 的连接。<ul>
<li>客户端发送 SYN 包（seq = j）到服务器，并进入 SYN_SEND 状态，等待服务器确认。</li>
<li>服务器收到 SYN 包，必须确认客户的 SYN（ACK = j+ 1），同时自己也发送一个 SYN 包（seq = k），即 SYN+ACK 包，此时服务器进入 SYN_RECV 状态。</li>
<li>客户端收到服务器的 SYN+ACK 包，向服务器发送确认包 ACK（ACK = k + 1），此包发送完毕，客户端和服务器进入 ESTABLISHED 状态，完成三次握手。</li>
</ul>
</li>
</ul>
</li>
<li><p>发送 HTTP / HTTPS 请求（建立 TLS 连接）</p>
<ul>
<li><img src="https://ask.qcloudimg.com/http-save/yehe-4474523/3ac0cf1dcd3100b2b96c55bf4e827adf.png?imageView2/2/w/1620" srcset="/img/loading.gif" lazyload alt="img"></li>
<li>TLS握手协议 <ol>
<li>客户端发出一个 client hello 消息，携带的信息包括：所支持的 SSL/TLS 版本列表；支持的与加密算法；所支持的数据压缩方法；随机数 A。</li>
<li>服务端响应一个 server hello 消息，携带的信息包括：协商采用的 SSL/TLS 版本号；会话 ID；随机数 B；服务端数字证书 serverCA；由于双向认证需求，服务端需要对客户端进行认证，会同时发送一个 client certificate request，表示请求客户端的证书。</li>
<li>客户端校验服务端的数字证书；校验通过之后发送随机数 C，该随机数称为 pre-master-key，使用数字证书中的公钥加密后发出；由于服务端请求了客户端的证书，客户端使用私钥加密一个随机数 clientRandom 随客户端的证书 clientCA 一并发出。</li>
<li>服务端校验客户端的证书，并成功将客户端加密的随机数 clientRandom 解密；根据随机数 A/随机数 B/随机数 C（pre-master-key） 产生动态密钥 master-key，加密一个 finish 消息发至客户端。</li>
<li>客户端根据同样的随机数和算法生成 master-key，加密一个 finish 消息发送至服务端。</li>
<li>服务端和客户端分别解密成功，至此握手完成，之后的数据包均采用 master-key 进行加密传输。</li>
</ol>
</li>
</ul>
</li>
<li><p>服务器响应请求</p>
<ul>
<li>当浏览器到 web 服务器的连接建立后，浏览器会发送一个初始的 HTTP GET 请求，请求目标通常是一个 HTML 文件。服务器收到请求后，将发回一个 HTTP 响应报文，内容包括相关响应头和 HTML 正文。</li>
</ul>
</li>
<li><p>浏览器解析渲染页面</p>
</li>
<li><p>HTTP 请求结束，断开 TCP 连接</p>
<ul>
<li>现在的页面为了优化请求的耗时，默认都会开启持久连接（keep-alive），那么一个 TCP 连接确切关闭的时机，是这个 tab 标签页关闭的时候。这个关闭的过程就是<strong>四次挥手</strong>。关闭是一个全双工的过程，发包的顺序是不一定的。一般来说是客户端主动发起的关闭，过程如下图所示： <ul>
<li>主动关闭方发送一个 FIN，用来关闭主动方到被动关闭方的数据传送，也就是主动关闭方告诉被动关闭方：我已经不会再给你发数据了（在 FIN 包之前发送出去的数据，如果没有收到对应的 ACK 确认报文，主动关闭方依然会重发这些数据），但此时主动关闭方还可以接受数据。</li>
<li>被动关闭方收到 FIN 包后，发送一个 ACK 给对方，确认序号为收到序号+1（与 SYN 相同，一个 FIN 占用一个序号）。</li>
<li>被动关闭方发送一个 FIN，用来关闭被动关闭方到主动关闭方的数据传送，也就是告诉主动关闭方，我的数据也发送完了，不会再给你发数据了。</li>
<li>主动关闭方收到 FIN 后，发送一个 ACK 给被动关闭方，确认序号为收到序号+1，至此，完成四次挥手。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="TCP-UDP协议"><a href="#TCP-UDP协议" class="headerlink" title="TCP/UDP协议"></a>TCP/UDP协议</h2><h3 id="TCP可靠性"><a href="#TCP可靠性" class="headerlink" title="TCP可靠性"></a>TCP可靠性</h3><ol>
<li><strong>基于数据块传输</strong> ：应用数据被分割成 TCP 认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段。</li>
<li><strong>对失序数据包重新排序以及去重</strong>：TCP 为了保证不发生丢包，就给每个包一个序列号，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据就可以实现数据包去重。</li>
<li><strong>校验和</strong> : TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。</li>
<li><strong>超时重传</strong> : 当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%A2%E5%8C%85">已丢失open in new window</a>并进行重传。</li>
<li><strong>流量控制</strong> : TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）。</li>
<li><strong>拥塞控制</strong> : 当网络拥塞时，减少数据的发送。</li>
</ol>
<h3 id="TCP半连接队列和全连接队列"><a href="#TCP半连接队列和全连接队列" class="headerlink" title="TCP半连接队列和全连接队列"></a>TCP半连接队列和全连接队列</h3><p>Q：什么是 TCP 半连接队列和全连接队列？</p>
<p>A：在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</p>
<ul>
<li>半连接队列，也称 SYN 队列；</li>
<li>全连接队列，也称 accept 队列；</li>
</ul>
<p>服务端收到客户端发起的 SYN 请求后，<strong>内核会把该连接存储到半连接队列</strong>，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，<strong>内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。</strong></p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg" srcset="/img/loading.gif" lazyload alt="半连接队列与全连接队列"></p>
<p>不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。</p>
<p>Q：如果 SYN 半连接队列已满，只能丢弃连接吗？</p>
<p>A：并不是这样，<strong>开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接</strong>，在前面我们源码分析也可以看到这点，当开启了 syncookies 功能就不会丢弃连接。</p>
<p>syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/39.jpg" srcset="/img/loading.gif" lazyload alt="开启 syncookies 功能"></p>
<h3 id="TCP-和-UDP-的区别"><a href="#TCP-和-UDP-的区别" class="headerlink" title="TCP 和 UDP 的区别"></a>TCP 和 UDP 的区别</h3><ul>
<li>TCP 是面向连接的，udp 是无连接的即发送数据前不需要先建立链接。</li>
<li>TCP 保证数据正确性，UDP 可能丢包，TCP 保证数据顺序，UDP 不保证。也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP 尽最大努力交付，即不保证可靠交付 Tcp 通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。</li>
<li><strong>TCP 只能是 1 对 1 的，UDP 支持 1 对 1,1 对多</strong>。</li>
<li><strong>TCP 是面向字节流，UDP 面向报文，UDP 具有较好的实时性，工作效率比 TCP 高</strong>.并且网络出现拥塞不会使得发送速率降低（因此会出现丢包，对实时的应用比如 IP 电话和视频会议等）。</li>
<li><strong>TCP 对系统资源要求较多，UDP 对系统资源要求较少</strong>。</li>
<li><strong>TCP 的首部较大为 20 字节，而 UDP 只有 8 字节</strong></li>
</ul>
<p>Q：可靠UDP传输</p>
<p>A：<a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/quic.html#quic-%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E7%9A%84">https://xiaolincoding.com/network/3_tcp/quic.html#quic-%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E7%9A%84</a></p>
<h3 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a>TCP三次握手</h3><p>Q：TCP三次握手过程，有什么状态，状态机如何变化？</p>
<p>A：客户端主动向服务端握手：<br>一开始客户端为 CLOSED 状态，服务端为 LISTEN 状态<br>首先客户端发送 SYN 报文，将 seq 置为 x，此时客户端状态转为 SYN_SENT<br>服务端收到后 SYN 报文后返回 SYN+ACK 报文，将 seq 置为 y，ack 置为 x+1，此时服务器状态转为 SYN_RCVD<br>客户端收到 SYN+ACK报文，此时客户端已经知道双方的收发都没有问题，但为了让服务端知道故返回 ACK 报文，将 ack 置为 y+1，此时客户端状态为 ESTABLISHED，并可以发送数据<br>服务端收到 ACK报文，此时服务端已经知道双方的收发都没有问题，此时服务端状态为 ESTABLISHED<br>至此连接建立成功</p>
<p><img src="https://pic.leetcode-cn.com/1658848039-ISJPNM-Untitled%201.png" srcset="/img/loading.gif" lazyload></p>
<p>Q：TCP握手的目的有哪些</p>
<p>A：确认双方的收发都没有问题，初始化序列号，确认窗口大小即mss等信息</p>
<p>Q：为什么是三次握手</p>
<p>1、<strong>防止旧的重复连接初始化造成混乱</strong></p>
<p>2、三次握手才能同步双方的初始序列号</p>
<p>3、避免资源浪费</p>
<p>Q：什么是 TIME_WAIT 状态，为什么需要 TIME_WAIT 状态？时间是多久，为什么？</p>
<p>A：四次挥手客户端接受到服务端 FIN 报文后返回 ACK 报文的状态<br>可以防止 ACK 报文丢失，服务器没有收到会重复发 FIN 报文<br>而 TIME_WAIT 的长度为 2*MSL 这样 ACK 丢失了，FIN 再次发送，在这时间里客户端还能收到 FIN 报文</p>
<p>Q：为什么 TCP 第二次握手的 SYN 和 ACK 要合并成一次？</p>
<p>A：分开两次发送，浪费资源</p>
<p>Q：为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？</p>
<ul>
<li>为了防止历史报文被下一个相同四元组的连接接收（主要方面）；</li>
<li>为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；</li>
</ul>
<h3 id="TCP四次挥手"><a href="#TCP四次挥手" class="headerlink" title="TCP四次挥手"></a>TCP四次挥手</h3><p>Q：TCP 四次挥手</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzMwLmpwZw?x-oss-process=image/format,png" srcset="/img/loading.gif" lazyload alt="客户端主动关闭连接 —— TCP 四次挥手"></p>
<ul>
<li>客户端打算关闭连接，此时会发送一个 TCP 首部 <code>FIN</code> 标志位被置为 <code>1</code> 的报文，也即 <code>FIN</code> 报文，之后客户端进入 <code>FIN_WAIT_1</code> 状态。</li>
<li>服务端收到该报文后，就向客户端发送 <code>ACK</code> 应答报文，接着服务端进入 <code>CLOSE_WAIT</code> 状态。</li>
<li>客户端收到服务端的 <code>ACK</code> 应答报文后，之后进入 <code>FIN_WAIT_2</code> 状态。</li>
<li>等待服务端处理完数据后，也向客户端发送 <code>FIN</code> 报文，之后服务端进入 <code>LAST_ACK</code> 状态。</li>
<li>客户端收到服务端的 <code>FIN</code> 报文后，回一个 <code>ACK</code> 应答报文，之后进入 <code>TIME_WAIT</code> 状态</li>
<li>服务端收到了 <code>ACK</code> 应答报文后，就进入了 <code>CLOSE</code> 状态，至此服务端已经完成连接的关闭。</li>
<li>客户端在经过 <code>2MSL</code> 一段时间后，自动进入 <code>CLOSE</code> 状态，至此客户端也完成连接的关闭。</li>
</ul>
<p>Q：为什么挥手需要四次</p>
<ul>
<li>关闭连接时，客户端向服务端发送 <code>FIN</code> 时，仅仅表示客户端不再发送数据了但是还能接收数据。</li>
<li>服务端收到客户端的 <code>FIN</code> 报文时，先回一个 <code>ACK</code> 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 <code>FIN</code> 报文给客户端来表示同意现在关闭连接。</li>
</ul>
<p>从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 <code>ACK</code> 和 <code>FIN</code> 一般都会分开发送，因此是需要四次挥手。</p>
<p>Q：可以变成三次挥手吗，什么情况下会出现三次挥手</p>
<p>A：当被动关闭方（上图的服务端）在 TCP 挥手过程中，「<strong>没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。</strong></p>
<p>Q：为什么 TIME_WAIT 等待的时间是 2MSL</p>
<p>A：网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以<strong>一来一回需要等待 2 倍的时间</strong>，相当于<strong>至少允许报文丢失一次</strong>。</p>
<p>Q：为什么需要 TIME_WAIT 状态？</p>
<ul>
<li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；<ul>
<li>为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 <code>2MSL</code> 时长，这个时间<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。</strong></li>
</ul>
</li>
<li>保证「被动关闭连接」的一方，能被正确的关闭；</li>
</ul>
<p>Q：TIME_WAIT 过多有什么危害？</p>
<p>A：占用系统资源，占用端口资源</p>
<p>Q：在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么</p>
<ul>
<li>如果处于 TIME_WAIT 状态的连接收到「合法的 SYN 」后，<strong>就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程</strong>。</li>
<li>如果处于 TIME_WAIT 状态的连接收到「非法的 SYN 」后，就会<strong>再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号（ack num），就回 RST 报文给服务端</strong>。</li>
</ul>
<p>Q：已建立连接的TCP，收到SYN会发生什么？</p>
<p>A：</p>
<p><strong>1. 客户端的 SYN 报文里的端口号与历史连接不相同</strong></p>
<p><strong>三次握手建立新连接</strong></p>
<p><strong>对于旧连接里的处于establish 状态的服务端</strong></p>
<p><strong>如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，客户内核会回RST报文，服务端收到后释放连接。</strong></p>
<p><strong>如果一直没有没有数据包发送，触发TCP保活机制，检测到客户端没有存活，接着就会释放连接</strong></p>
<p><strong>2. 客户端的 SYN 报文里的端口号与历史连接相同</strong></p>
<p><strong>处于 establish 状态的服务端如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。</strong></p>
<p><strong>接着，客户端收到这个 Challenge ACK，发现序列号并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。</strong></p>
<p>Q：TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？</p>
<p>A：HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。</p>
<p>TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。</p>
<p>也就是默认情况下一条TCP连接在2小时（<strong>7200秒</strong>）都没有报文交换后，会开始进行保活探测，若再经过9*75秒=<strong>11分钟15秒</strong>的循环探测都未收到探测响应，即共计：2小时11分钟15秒后会自动断开TCP连接。</p>
<p>Q：TCP 是面向字节流的协议，UDP 是面向报文的协议？这里的「面向字节流」和「面向报文」该如何理解。</p>
<p>A：一个完整的用户消息被拆分成多个 TCP 报文进行传输。因此，<strong>我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议</strong>。</p>
<h3 id="TCP粘包"><a href="#TCP粘包" class="headerlink" title="TCP粘包"></a>TCP粘包</h3><p>Q：什么是tcp粘包</p>
<p>A：当两个消息的某个部分内容被分到同一个 TCP 报文的现象就叫tcp粘包</p>
<p>Q：如何解决tcp粘包</p>
<ul>
<li>固定长度的消息；</li>
<li>特殊字符作为边界；</li>
<li>自定义消息结构。</li>
</ul>
<h3 id="TCP队头阻塞问题"><a href="#TCP队头阻塞问题" class="headerlink" title="TCP队头阻塞问题"></a>TCP队头阻塞问题</h3><p>TCP数据包是有序传输，中间一个数据保丢失，会等待该数据包重传</p>
<h3 id="TCP滑动窗口"><a href="#TCP滑动窗口" class="headerlink" title="TCP滑动窗口"></a>TCP滑动窗口</h3><h3 id="TCP流量控制"><a href="#TCP流量控制" class="headerlink" title="TCP流量控制"></a>TCP流量控制</h3><p><strong>TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。</strong> 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。</p>
<p><strong>为什么需要流量控制?</strong> 这是因为双方在通信的时候，发送方的速率与接收方的速率是不一定相等，如果发送方的发送速率太快，会导致接收方处理不过来。如果接收方处理不过来的话，就只能把处理不过来的数据存在 <strong>接收缓冲区(Receiving Buffers)</strong> 里（失序的数据包也会被存放在缓存区里）。如果缓存区满了发送方还在狂发数据的话，接收方只能把收到的数据包丢掉。出现丢包问题的同时又疯狂浪费着珍贵的网络资源。因此，我们需要控制发送方的发送速率，让接收方与发送方处于一种动态平衡才好。</p>
<h3 id="TCP拥塞控制"><a href="#TCP拥塞控制" class="headerlink" title="TCP拥塞控制"></a>TCP拥塞控制</h3><ul>
<li><strong>慢启动：</strong> 慢启动算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。<strong>拥塞窗口</strong>初始值为 1，每经过一个传播轮次，<strong>拥塞窗口</strong>加倍。</li>
<li><strong>拥塞避免：</strong> 拥塞避免算法的思路是让 <strong>拥塞窗口</strong>缓慢增大，即每经过一个往返时间 RTT 就把发送放的 <strong>拥塞窗口</strong>加 1.</li>
<li><strong>快重传与快恢复：</strong> 在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。</li>
</ul>
<h3 id="TCP-SYN洪水攻击"><a href="#TCP-SYN洪水攻击" class="headerlink" title="TCP SYN洪水攻击"></a>TCP SYN洪水攻击</h3><p>Q：SYN Flood 的原理？有哪些防范的方法？</p>
<p>A：客户端发送三次握手的第一个 SYN 报文后收到服务器的报文却不回应，从而导致服务器的半开资源浪费直到超时释放</p>
<p>可以使用 SYN Cookie，即通过将源目地址及 IP 地址和端口号哈希为序列号，将返回的 ACK-1 得到原来的序列号判断是否正确，直到连接建立才分配资源</p>
<ul>
<li>增大半连接队列；</li>
<li>开启 tcp_syncookies 功能</li>
<li>减少 SYN+ACK 重传次数</li>
</ul>
<h3 id="TCP首部"><a href="#TCP首部" class="headerlink" title="TCP首部"></a>TCP首部</h3><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/8.jpg" srcset="/img/loading.gif" lazyload alt="TCP 包头格式"></p>
<h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><p>Q：SYN 报文什么时候情况下会被丢弃？</p>
<p>A：</p>
<ul>
<li>TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃</li>
</ul>
<p>Q：HTTP 长连接和 TCP 长连接有区别</p>
<p>A：HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。</p>
<p>TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。</p>
<h2 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a>HTTP协议</h2><p>Q：什么是HTTP协议</p>
<p>A：HTTP 是超文本传输协议，<strong>HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」</strong>。</p>
<p>Q：HTTP常见的状态码</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" srcset="/img/loading.gif" lazyload alt=" 五大类 HTTP 状态码 "></p>
<ul>
<li>「<strong>200 OK</strong>」是最常见的成功状态码，表示一切正常。如果是非 <code>HEAD</code> 请求，服务器返回的响应头都会有 body 数据。</li>
<li>「<strong>204 No Content</strong>」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。</li>
<li>「<strong>206 Partial Content</strong>」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。</li>
</ul>
<p><code>3xx</code> 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是<strong>重定向</strong>。</p>
<ul>
<li>「<strong>301 Moved Permanently</strong>」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。</li>
<li>「<strong>302 Found</strong>」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。</li>
</ul>
<p>301 和 302 都会在响应头里使用字段 <code>Location</code>，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。</p>
<ul>
<li>「<strong>304 Not Modified</strong>」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。</li>
</ul>
<p><code>4xx</code> 类状态码表示客户端发送的<strong>报文有误</strong>，服务器无法处理，也就是错误码的含义。</p>
<ul>
<li>「<strong>400 Bad Request</strong>」表示客户端请求的报文有错误，但只是个笼统的错误。</li>
<li>「<strong>403 Forbidden</strong>」表示服务器禁止访问资源，并不是客户端的请求出错。</li>
<li>「<strong>404 Not Found</strong>」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。</li>
</ul>
<p><code>5xx</code> 类状态码表示客户端请求报文正确，但是<strong>服务器处理时内部发生了错误</strong>，属于服务器端的错误码。</p>
<ul>
<li>「<strong>500 Internal Server Error</strong>」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。</li>
<li>「<strong>501 Not Implemented</strong>」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。</li>
<li>「<strong>502 Bad Gateway</strong>」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。</li>
<li>「<strong>503 Service Unavailable</strong>」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。</li>
</ul>
<p>Q：HTTP常见字段有哪些</p>
<ul>
<li>Host：用来指定服务器的域名</li>
<li>Content-Length 字段：用来表明本次回应的数据长度</li>
<li><em>Connection</em>：常用于客户端要求服务器使用「 HTTP 长连接」机制，以便其他请求复用</li>
<li><em>Content-Type 字段</em>：用于服务器回应时，告诉客户端，本次数据是什么格式</li>
<li><em>Content-Encoding 字段</em>：说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式</li>
<li>Accept字段：表明自己可以接收哪些数据格式</li>
<li>Accept-Encoding 字段：说明自己可以接受哪些压缩方法</li>
</ul>
<p>Q：GET 和 POST 有什么区别？</p>
<p>A：<strong>GET 的语义是从服务器获取指定的资源</strong>，GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制</p>
<p><strong>POST 的语义是根据请求负荷（报文body）对指定的资源做出处理</strong>，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中， body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。</p>
<p>Q：HTTP不同版本的区别</p>
<p>A：HTTP不同版本区别（1.1：长连接与管道传输；2：并发传输（多个 stream 复用一个 TCP 连接，为解决队头阻塞做出的努力）、二进制传输（不光支持 ASCII 码内容传输，对消息类型适用性好）、头部压缩（静态表，动态表用索引值代替字段，哈夫曼压缩字段中的内容）、服务器主动推送；3：改 TCP-based 为 UDP-based（QUIC）（完全解决队头阻塞），用连接号标识连接（解决TCP用四元组标识通信在网络切换时发生的开销））</p>
<p>Q：HTTP1.0 、1.1和2.0 的区别和差异是什么</p>
<p>A：作者：MangataTS<br>链接：<a target="_blank" rel="noopener" href="https://www.nowcoder.com/discuss/1077628">https://www.nowcoder.com/discuss/1077628</a><br>来源：牛客网</p>
<blockquote>
<ul>
<li>《HTTP1.0和1.1的区别》 </li>
<li>HTTP1.1 默认开启长连接（<code>keep-alive</code>） 而HTTP1.0需要添加参数，在一定程度上减少了建立和关闭连接的消耗和延迟 </li>
<li>HTTP1.0中存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。HTTP1.1支持只发送header信息（不带任何body信息），如果服务器认为客户端有权限请求服务器，则返回100，客户端接收到100才开始把请求body发送到服务器；如果返回401，客户端就可以不用发送请求body了节约了带宽。 </li>
<li>HTTP1.0中认为每台服务器只有一个唯一的IP地址，因此请求头中的URL中并没有传递主机名，因此HTTP1.0没有host域，但是HTTP1.1的请求消息必须有host域（host域其实就是一个记录IP和域名的文件，可以加快解析速度） </li>
<li>在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。 </li>
<li>在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 </li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>《HTTP1.1和2.0的区别》 </li>
<li>HTTP2.0使用多路复用的技术，做到同一个连接并发处理多个请求，并且并发请求的数量也比HTTP1.1大了好几个数量级，要比HTTP1.1多建几个TCP连接的开销更小 </li>
<li>HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。 </li>
<li><strong>支持服务器推送</strong> ，为了改善延迟，HTTP2.0引入了server push，它允许服务端推送资源给浏览器，在 <strong>浏览器明确地请求之前</strong> ，免得客户端再次创建连接发送请求到服务器端获取。这样客户端可以直接从本地加载这些资源，不用再通过网络。 </li>
<li>HTTP2.0采用二进制格式传输数据</li>
</ul>
</blockquote>
<p>Q：为什么数据传输是用的对称加密</p>
<p>A：</p>
<p>非对称加密的加解密效率是非常低的，而 http 的应用场景中通常端与端之间存在大量的交互，非对称加密的效率是无法接受的 </p>
<p>在 HTTPS 的场景中只有服务端保存了私钥，一对公私钥只能实现单向的加解密，所以 HTTPS 中内容传输加密采取的是对称加密，而不是非对称加密。</p>
<h3 id="HTTP1-1"><a href="#HTTP1-1" class="headerlink" title="HTTP1.1"></a>HTTP1.1</h3><p>HTTP/1.1 相比 HTTP/1.0 性能上的改进：</p>
<ul>
<li>使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。</li>
<li>支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</li>
</ul>
<p>但 HTTP/1.1 还是有性能瓶颈：</p>
<ul>
<li>请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 <code>Body</code> 的部分；</li>
<li>发送冗长的首部。每次互相发送相同的首部造成的浪费较多；</li>
<li>服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；</li>
<li>没有请求优先级控制；</li>
<li>请求只能从客户端开始，服务器只能被动响应。</li>
</ul>
<h4 id="持久连接"><a href="#持久连接" class="headerlink" title="持久连接"></a>持久连接</h4><ul>
<li>HTTP1.1 默认开启长连接（<code>keep-alive</code>） 而HTTP1.0需要添加参数，在一定程度上减少了建立和关闭连接的消耗和延迟</li>
</ul>
<h4 id="持久连接的限制和规则"><a href="#持久连接的限制和规则" class="headerlink" title="持久连接的限制和规则"></a>持久连接的限制和规则</h4><h4 id="管道化连接"><a href="#管道化连接" class="headerlink" title="管道化连接"></a>管道化连接</h4><p>HTTP 管线化可以克服同域并行请求限制带来的阻塞，它是建立在<strong>持久连接</strong>之上，是把所有请求一并发给服务器，但是服务器需要按照<strong>顺序一个一个响应</strong>，而不是等到一个响应回来才能发下一个请求，这样就节省了很多请求到服务器的时间。不过，HTTP 管线化<strong>仍旧</strong>有阻塞的问题，若上一响应迟迟不回，<strong>后面的响应</strong>都会被阻塞到。</p>
<h4 id="队头阻塞问题"><a href="#队头阻塞问题" class="headerlink" title="队头阻塞问题"></a>队头阻塞问题</h4><p>HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了<strong>队头阻塞</strong>的问题。</p>
<h3 id="HTTP2-0"><a href="#HTTP2-0" class="headerlink" title="HTTP2.0"></a>HTTP2.0</h3><p>HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/25-HTTP2.png" srcset="/img/loading.gif" lazyload alt="HTT/1 ~ HTTP/2"></p>
<h4 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h4><ul>
<li>HTTP2.0使用多路复用的技术，做到同一个连接并发处理多个请求，并且并发请求的数量也比HTTP1.1大了好几个数量级，要比HTTP1.1多建几个TCP连接的开销更小</li>
</ul>
<h4 id="头部压缩"><a href="#头部压缩" class="headerlink" title="头部压缩"></a>头部压缩</h4><p>HTTP/2 会<strong>压缩头</strong>（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你<strong>消除重复的部分</strong>。</p>
<p>这就是所谓的 <code>HPACK</code> 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就<strong>提高速度</strong>了。</p>
<h4 id="二进制传输"><a href="#二进制传输" class="headerlink" title="二进制传输"></a>二进制传输</h4><p>存在于连接中的一个虚拟通道。流可以承载双向消息，每个流都有一个唯一的整数 ID。 HTTP/2 长连接中的数据包是不按请求-响应顺序发送的，一个完整的请求或响应(称一个数据流 stream，每个数据流都有一个独一无二的编号)可能会分成非连续多次发送。</p>
<p>HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了<strong>二进制格式</strong>，头信息和数据体都是二进制，并且统称为帧（frame）：<strong>头信息帧（Headers Frame）和数据帧（Data Frame）</strong>。</p>
<p>这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这<strong>增加了数据传输的效率</strong>。</p>
<h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h4><h4 id="服务端推送"><a href="#服务端推送" class="headerlink" title="服务端推送"></a>服务端推送</h4><p><strong>支持服务器推送</strong> ，为了改善延迟，HTTP2.0引入了server push，它允许服务端推送资源给浏览器，在 <strong>浏览器明确地请求之前</strong> ，免得客户端再次创建连接发送请求到服务器端获取。这样客户端可以直接从本地加载这些资源，不用再通过网络。</p>
<h4 id="队头阻塞"><a href="#队头阻塞" class="headerlink" title="队头阻塞"></a>队头阻塞</h4><p>HTTP/2 多个请求是跑在一个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求。</p>
<h3 id="HTTP3-0"><a href="#HTTP3-0" class="headerlink" title="HTTP3.0"></a>HTTP3.0</h3><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/27-HTTP3.png" srcset="/img/loading.gif" lazyload alt="HTTP/1 ~ HTTP/3"></p>
<h4 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h4><h4 id="连接迁移"><a href="#连接迁移" class="headerlink" title="连接迁移"></a>连接迁移</h4><p>在前面我们提到，基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzEwLmpwZw?x-oss-process=image/format,png" srcset="/img/loading.gif" lazyload alt="TCP 四元组"></p>
<p>那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接，而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p>
<p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p>
<h4 id="无队头阻塞"><a href="#无队头阻塞" class="headerlink" title="无队头阻塞"></a>无队头阻塞</h4><p>QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。</p>
<p>由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心。</p>
<p>不过 QUIC 协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。</p>
<p>而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p>
<p><strong>所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。</strong></p>
<h3 id="HTTP缓存"><a href="#HTTP缓存" class="headerlink" title="HTTP缓存"></a>HTTP缓存</h3><h4 id="强制缓存"><a href="#强制缓存" class="headerlink" title="强制缓存"></a>强制缓存</h4><p>强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。</p>
<p>强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：</p>
<ul>
<li><code>Cache-Control</code>， 是一个相对时间；</li>
<li><code>Expires</code>，是一个绝对时间；</li>
</ul>
<p>如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，<strong>Cache-Control的优先级高于 Expires</strong> 。</p>
<p>Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：</p>
<ul>
<li>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；</li>
<li>浏览器再次请求访问服务器中的该资源时，会先<strong>通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期</strong>，如果没有，则使用该缓存，否则重新请求服务器；</li>
<li>服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。</li>
</ul>
<h4 id="协商缓存"><a href="#协商缓存" class="headerlink" title="协商缓存"></a><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/2_http/http_interview.html#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%8F%E5%95%86%E7%BC%93%E5%AD%98">协商缓存</a></h4><p>当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 <code>304</code>，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。</p>
<p><strong>协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存</strong>。</p>
<h3 id="HTTP报文格式"><a href="#HTTP报文格式" class="headerlink" title="HTTP报文格式"></a>HTTP报文格式</h3><p><img src="http://s2.51cto.com/wyfs02/M02/59/16/wKioL1THNfahGAkDAAFu--59S3M173.jpg" srcset="/img/loading.gif" lazyload alt="HTTP 请求报文由请求行、请求头部、空行 和 请求包体 4 个部分组成"></p>
<h3 id="HTTP和HTTPS"><a href="#HTTP和HTTPS" class="headerlink" title="HTTP和HTTPS"></a>HTTP和HTTPS</h3><p>Q：HTTP缺陷</p>
<p>A：</p>
<ul>
<li><strong>窃听风险</strong>，比如通信链路上可以获取通信内容，用户号容易没。</li>
<li><strong>篡改风险</strong>，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。</li>
<li><strong>冒充风险</strong>，比如冒充淘宝网站，用户钱容易没。</li>
</ul>
<p>Q：HTTPS 是如何解决上面的三个风险的？</p>
<p>A：</p>
<ul>
<li><strong>混合加密</strong>的方式实现信息的<strong>机密性</strong>，解决了窃听的风险。</li>
<li><strong>摘要算法</strong>的方式来实现<strong>完整性</strong>，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。</li>
<li><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D.png" srcset="/img/loading.gif" lazyload alt="img"></li>
<li>将服务器公钥放入到<strong>数字证书</strong>中，解决了冒充的风险。</li>
</ul>
<p>Q：TLS 协议建立的详细流程</p>
<p>A：</p>
<p><em>1. ClientHello</em></p>
<p>首先，由客户端向服务器发起加密通信请求，也就是 <code>ClientHello</code> 请求。</p>
<p>在这一步，客户端主要向服务器发送以下信息：</p>
<p>（1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。</p>
<p>（2）客户端生产的随机数（<code>Client Random</code>），后面用于生成「会话秘钥」条件之一。</p>
<p>（3）客户端支持的密码套件列表，如 RSA 加密算法。</p>
<p><em>2. SeverHello</em></p>
<p>服务器收到客户端请求后，向客户端发出响应，也就是 <code>SeverHello</code>。服务器回应的内容有如下内容：</p>
<p>（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。</p>
<p>（2）服务器生产的随机数（<code>Server Random</code>），也是后面用于生产「会话秘钥」条件之一。</p>
<p>（3）确认的密码套件列表，如 RSA 加密算法。</p>
<p>（4）服务器的数字证书。</p>
<p><em>3.客户端回应</em></p>
<p>客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。</p>
<p>如果证书没有问题，客户端会<strong>从数字证书中取出服务器的公钥</strong>，然后使用它加密报文，向服务器发送如下信息：</p>
<p>（1）一个随机数（<code>pre-master key</code>）。该随机数会被服务器公钥加密。</p>
<p>（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p>
<p>（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。</p>
<p>上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。</p>
<p><strong>服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」</strong>。</p>
<p><em>4. 服务器的最后回应</em></p>
<p>服务器收到客户端的第三个随机数（<code>pre-master key</code>）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。</p>
<p>然后，向客户端发送最后的信息：</p>
<p>（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p>
<p>（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。</p>
<p>至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。</p>
<p>Q：客户端校验数字证书的流程是怎样的？</p>
<p>A：</p>
<ul>
<li>首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；</li>
<li>通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature（证书签名） 内容，得到一个 Hash 值 H2 ；</li>
<li>最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。</li>
</ul>
<p>Q：CA 签发证书的过程</p>
<p>A：</p>
<ul>
<li>首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；</li>
<li>然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；</li>
<li>最后将 Certificate Signature 添加在文件证书上，形成数字证书；</li>
</ul>
<h2 id="ARP协议"><a href="#ARP协议" class="headerlink" title="ARP协议"></a>ARP协议</h2><p>Q：那么 ARP 又是如何知道对方 MAC 地址的呢？</p>
<p>A：</p>
<p>简单地说，ARP 是借助 <strong>ARP 请求与 ARP 响应</strong>两种类型的包确定 MAC 地址的。</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/34.jpg" srcset="/img/loading.gif" lazyload alt="ARP 广播"></p>
<ul>
<li>主机会通过<strong>广播发送 ARP 请求</strong>，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。</li>
<li>当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 <strong>ARP 响应包</strong>返回给主机。</li>
</ul>
<p>操作系统通常会把第一次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。</p>
<p>不过，MAC 地址的缓存是有一定期限的，超过这个期限，缓存的内容将被清除。</p>
<h2 id="NAT协议"><a href="#NAT协议" class="headerlink" title="NAT协议"></a>NAT协议</h2><p>Q：什么是NAT协议</p>
<p>A：</p>
<p>NAT 网络地址转换 把私有ip转换成公有ip 转换表里面存 IP地址 + 端口号 NAT转换表在NAT路由器上面生成</p>
<p><img src="https://blog.reginvolver.cn/wp-content/uploads/2022/10/image-1666948779530.png" srcset="/img/loading.gif" lazyload alt="file"></p>
<h2 id="RARP协议"><a href="#RARP协议" class="headerlink" title="RARP协议"></a>RARP协议</h2><p>Q：RARP 协议你知道是什么吗？</p>
<p>A：ARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是<strong>已知 MAC 地址求 IP 地址</strong>。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。</p>
<p>通常这需要架设一台 <code>RARP</code> 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着：</p>
<ul>
<li>该设备会发送一条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。</li>
<li>RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。</li>
</ul>
<p>最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/35.jpg" srcset="/img/loading.gif" lazyload alt="RARP"></p>
<p>Q：交换机和路由器表中保存的什么</p>
<p><img src="https://blog.reginvolver.cn/wp-content/uploads/2022/10/image-1666948484336.png" srcset="/img/loading.gif" lazyload alt="file"></p>
<p><img src="https://blog.reginvolver.cn/wp-content/uploads/2022/10/image-1666948518233.png" srcset="/img/loading.gif" lazyload alt="file"></p>
<h4 id=""><a href="#" class="headerlink" title=""></a></h4><h2 id="WebSocket协议"><a href="#WebSocket协议" class="headerlink" title="WebSocket协议"></a>WebSocket协议</h2><p>Q：WebSocket 也是基于Http协议的对吧</p>
<p>A：WebSocket在建立连接的时候是使用的HTTP协议，建立连接之后就是自己的WebSocket协议了</p>
<p>Q：既然有 HTTP 协议，为什么还要有 WebSocket</p>
<p>A：</p>
<p>它适用于<strong>需要服务器和客户端（浏览器）频繁交互</strong>的大部分场景，比如网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。</p>
<ul>
<li>TCP 协议本身是<strong>全双工</strong>的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是<strong>半双工</strong>的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。</li>
<li>在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用<strong>定时轮询或者长轮询</strong>的方式实现<strong>服务器推送</strong>(comet)的效果。</li>
<li>对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。</li>
<li>WebSocket 和 socket 几乎没有任何关系，只是叫法相似。</li>
<li>正因为各个浏览器都支持 HTTP协 议，所以 WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200527233246458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xMODQ1ODc2NDI1,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" lazyload alt="img"></p>
<h4 id="客户端请求报文"><a href="#客户端请求报文" class="headerlink" title="客户端请求报文"></a>客户端请求报文</h4><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs http"><span class="hljs-keyword">GET</span> <span class="hljs-string">/uin=xxxxxxxx&amp;app=xxxxxxxxx&amp;token=XXXXXXXXXXXX</span> <span class="hljs-meta">HTTP/1.1</span><br><span class="hljs-attribute">Host</span><span class="hljs-punctuation">: </span>server.example.cn:443<br><span class="hljs-attribute">Connection</span><span class="hljs-punctuation">: </span>Upgrade<br><span class="hljs-attribute">Pragma</span><span class="hljs-punctuation">: </span>no-cache<br><span class="hljs-attribute">Cache-Control</span><span class="hljs-punctuation">: </span>no-cache<br><span class="hljs-attribute">User-Agent</span><span class="hljs-punctuation">: </span>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36<br><span class="hljs-attribute">Upgrade</span><span class="hljs-punctuation">: </span>websocket<br><span class="hljs-attribute">Sec-WebSocket-Version</span><span class="hljs-punctuation">: </span>13<br><span class="hljs-attribute">Accept-Encoding</span><span class="hljs-punctuation">: </span>gzip, deflate<br><span class="hljs-attribute">Accept-Language</span><span class="hljs-punctuation">: </span>zh-CN,zh;q=0.9<br><span class="hljs-attribute">Cookie</span><span class="hljs-punctuation">: </span>user_id=XXXXX<br><span class="hljs-attribute">Sec-WebSocket-Key</span><span class="hljs-punctuation">: </span>1/2hTi/+eNURiekpNI4k5Q==<br><span class="hljs-attribute">Sec-WebSocket-Extensions</span><span class="hljs-punctuation">: </span>permessage-deflate; client_max_window_bits<br><span class="hljs-attribute">Sec-WebSocket-Protocol</span><span class="hljs-punctuation">: </span>binary, base64<br></code></pre></td></tr></table></figure>

<p>第一行为为请求的方法，类型必须为GET，协议版本号必须大于1.1<br>Upgrade字段必须包含，值为websocket<br>Connection字段必须包含，值为Upgrade<br>Sec-WebSocket-Key字段必须包含 ，记录着握手过程中必不可少的键值。<br>Sec-WebSocket-Protocol字段必须包含 ，记录着使用的子协议</p>
<h4 id="服务端响应报文及实现"><a href="#服务端响应报文及实现" class="headerlink" title="服务端响应报文及实现"></a>服务端响应报文及实现</h4><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs http"><span class="hljs-meta">HTTP/1.1</span> <span class="hljs-number">101</span> Switching Protocols<br><span class="hljs-attribute">Upgrade</span><span class="hljs-punctuation">: </span>websocket<br><span class="hljs-attribute">Connection</span><span class="hljs-punctuation">: </span>Upgrade<br><span class="hljs-attribute">Sec-WebSocket-Accept</span><span class="hljs-punctuation">: </span>HSmrc0sMlYUkAGmm5OPpG2HaGWk=<br><span class="hljs-attribute">Sec-WebSocket-Protocol</span><span class="hljs-punctuation">: </span>chat<br></code></pre></td></tr></table></figure>

<p>1、首先，101 状态码表示服务器已经理解了客户端的请求，并将通过 <code>Upgrade</code> 消息头通知客户端采用不同的协议来完成这个请求；</p>
<p>2、然后，<code>Sec-WebSocket-Accept</code> 这个则是经过服务器确认，并且加密过后的 <code>Sec-WebSocket-Key</code>；</p>
<p>3、最后，<code>Sec-WebSocket-Protocol</code> 则是表示最终使用的协议。</p>
<p>握手成功后，通信不再使用HTTP协议，而采用WebSocket独立的数据帧。如下图所示，为协议帧格式：</p>
<p><img src="https://img-blog.csdnimg.cn/20200527233345809.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xMODQ1ODc2NDI1,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" lazyload alt="img"></p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">FIN</span>，指明Frame是否是一个Message里最后Frame（之前说过一个Message可能又多个Frame组成）；<span class="hljs-number">1</span>bit，是否为信息的最后一帧<br><span class="hljs-attribute">RSV1</span>-<span class="hljs-number">3</span>，默认是<span class="hljs-number">0</span> (必须是<span class="hljs-number">0</span>)，除非有扩展定义了非零值的意义。<br><span class="hljs-attribute">Opcode</span>，这个比较重要，有如下取值是被协议定义的<br>				<span class="hljs-attribute">0x00</span> denotes a continuation frame<br>				<span class="hljs-attribute">0x01</span> 表示一个text frame<br>				<span class="hljs-attribute">0x02</span> 表示一个binary frame<br>				<span class="hljs-attribute">0x03</span> ~~ <span class="hljs-number">0</span>x07 are reserved for further non-control frames,为将来的非控制消息片段保留测操作码<br>				<span class="hljs-attribute">0x08</span> 表示连接关闭<br>				<span class="hljs-attribute">0x09</span> 表示 ping (心跳检测相关)<br>				<span class="hljs-attribute">0x0a</span> 表示 pong (心跳检测相关)<br>				<span class="hljs-attribute">0x0b</span> ~~ <span class="hljs-number">0</span>x0f are reserved for further control frames,为将来的控制消息片段保留的操作码<br><span class="hljs-attribute">Mask</span>，这个是指明“payload data”是否被计算掩码。这个和后面的Masking-key有关，如果设置为<span class="hljs-number">1</span>,掩码键必须放在masking-key区域，客户端发送给服务端的所有消息，此位的值都是<span class="hljs-number">1</span>；<br><span class="hljs-attribute">Payload</span> len，数据的长度，<br><span class="hljs-attribute">Masking</span>-key，<span class="hljs-number">0</span>或者<span class="hljs-number">4</span>bit，只有当MASK设置为<span class="hljs-number">1</span>时才有效。，给一个Websocket中掩码的意义<br><span class="hljs-attribute">Payload</span> data，帧真正要发送的数据，可以是任意长度，但尽管理论上帧的大小没有限制，但发送的数据不能太大，否则会导致无法高效利用网络带宽，正如上面所说Websocket提供分片。<br><span class="hljs-attribute">Extension</span> data：扩展数据，如果客户端和服务端没有特殊的约定，那么扩展数据长度始终为<span class="hljs-number">0</span><br><span class="hljs-attribute">Application</span> data：应用数据，<br></code></pre></td></tr></table></figure>

<p>1、WebSocket 是双向的 -使用 WebSocket 客户端或服务器可以发起消息发送。</p>
<p>2、WebSocket 是全双工的 -客户端和服务器通信是相互独立的。</p>
<p>3、单个 TCP 连接 -初始连接使用 HTTP，然后将此连接升级到基于套接字的连接。然后这个单一连接用于所有未来的通信</p>
<p>4、Light -与 http 相比，WebSocket 消息数据交换要轻得多。</p>
<h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><p>Q：数据库三范式</p>
<p>A：</p>
<p>第一范式：强调的是列的原子性，列不能分成其他几列，第一范式就是无重复的域。 </p>
<p>  第二范式：首先是在第一范式的基础上，另外包含两部分的内容，一是表必须有主键，二是没有包含在主键中的列必须完全依赖于主键，二不能只依赖于主键的一部分。 </p>
<p>  第三范式：在第二范式的基础之上，非主键列必须直接依赖于主键不能存在传递依赖。</p>
<h3 id="引擎"><a href="#引擎" class="headerlink" title="引擎"></a>引擎</h3><p>Q：MyISAM 和 InnoDB 的区别是什么？</p>
<p>A：</p>
<p><strong>1.是否支持行级锁</strong></p>
<p>MyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。</p>
<p>也就说，MyISAM 一锁就是锁住了整张表，这在并发写的情况下是多么滴憨憨啊！这也是为什么 InnoDB 在并发写的时候，性能更牛皮了！</p>
<p><strong>2.是否支持事务</strong></p>
<p>MyISAM 不提供事务支持。</p>
<p>InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别，具有提交(commit)和回滚(rollback)事务的能力。并且，InnoDB 默认使用的 REPEATABLE-READ（可重读）隔离级别是可以解决幻读问题发生的（基于 MVCC 和 Next-Key Lock）。</p>
<p><strong>3.是否支持外键</strong></p>
<p>MyISAM 不支持，而 InnoDB 支持。</p>
<p><strong>4.是否支持数据库异常崩溃后的安全恢复</strong></p>
<p>MyISAM 不支持，而 InnoDB 支持。</p>
<p>使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 <code>redo log</code> 。</p>
<p><strong>5.是否支持 MVCC</strong></p>
<p>MyISAM 不支持，而 InnoDB 支持。</p>
<p>讲真，这个对比有点废话，毕竟 MyISAM 连行级锁都不支持。MVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。</p>
<p><strong>6.索引实现不一样。</strong></p>
<p>虽然 MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。</p>
<p>InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。</p>
<h3 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B+Tree"></a>B+Tree</h3><p>Q：B+树特点</p>
<ul>
<li>每个结点至多有m个子女;</li>
<li>非根节点关键值个数范围：⌈m/2⌉ - 1 &lt;= k &lt;= m-1</li>
<li>相邻叶子节点是通过指针连起来的，并且是关键字大小排序的。</li>
</ul>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p>Q：索引的分类</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/%E7%B4%A2%E5%BC%95/%E7%B4%A2%E5%BC%95%E5%88%86%E7%B1%BB.drawio.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<ul>
<li>按「数据结构」分类：<strong>B+tree索引、Hash索引、Full-text索引</strong>。</li>
<li>按「物理存储」分类：<strong>聚簇索引（主键索引）、二级索引（辅助索引）</strong>。</li>
<li>按「字段特性」分类：<strong>主键索引、唯一索引、普通索引、前缀索引</strong>。</li>
<li>按「字段个数」分类：<strong>单列索引、联合索引</strong>。</li>
</ul>
<p>Q：什么叫做回表</p>
<p>A：<strong>如果某个查询语句使用了二级索引，但是查询的数据不是主键值，这时在二级索引找到主键值后，需要去聚簇索引中获得数据行，这个过程就叫作「回表」</strong></p>
<p>Q：什么是覆盖索引</p>
<p>A：覆盖索引是select的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖。</p>
<p>Q：辅助索引的叶子节点存的是啥啊？</p>
<p>A：辅助索引的叶子节点保存的是对应的主键键值，而另外一种存储引擎myisam叶子节点保存的是记录的地址</p>
<p>Q：为什么 MySQL InnoDB 选择 B+tree 作为索引的数据结构？</p>
<p><em><strong>1、B+Tree vs B Tree</strong></em></p>
<p>B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。</p>
<p>另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。</p>
<p><em><strong>2、B+Tree vs 二叉树</strong></em></p>
<p>对于有 N 个叶子节点的 B+Tree，其搜索复杂度为<code>O(logdN)</code>，其中 d 表示节点允许的最大子节点个数为 d 个。</p>
<p>在实际的应用当中， d 值是大于100的，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 3<del>4 层左右，也就是说一次数据查询操作只需要做 3</del>4 次的磁盘 I/O 操作就能查询到目标数据。</p>
<p>而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 <code>O(logN)</code>，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。</p>
<p><em><strong>3、B+Tree vs Hash</strong></em></p>
<p>Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。</p>
<p>但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。</p>
<p>Q：索引的缺陷</p>
<ul>
<li>需要占用物理空间，数量越大，占用空间越大；</li>
<li>创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大；</li>
<li>会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。</li>
</ul>
<p>Q：什么时候适用索引，什么时候不适用</p>
<p><strong>什么时候适用索引？</strong></p>
<ul>
<li>字段有唯一性限制的，比如商品编码；</li>
<li>经常用于 <code>WHERE</code> 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。</li>
<li>经常用于 <code>GROUP BY</code> 和 <code>ORDER BY</code> 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。</li>
</ul>
<p><strong>什么时候不需要创建索引？</strong></p>
<ul>
<li><code>WHERE</code> 条件，<code>GROUP BY</code>，<code>ORDER BY</code> 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。</li>
<li>字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。</li>
<li>表数据太少的时候，不需要创建索引；</li>
<li>经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。</li>
</ul>
<p>Q：索引的优化</p>
<ul>
<li>前缀索引优化；</li>
<li>覆盖索引优化；</li>
<li>主键索引最好是自增的；</li>
<li>防止索引失效；</li>
</ul>
<p>Q：索引失效的情况</p>
<ul>
<li>当我们使用左或者左右模糊匹配的时候，也就是 <code>like %xx</code> 或者 <code>like %xx%</code>这两种方式都会造成索引失效；</li>
<li>当我们在查询条件中对索引列使用函数，就会导致索引失效。</li>
<li>当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。</li>
<li>MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。</li>
<li>联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。</li>
<li>在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。</li>
</ul>
<p>Q：InnoDB 是如何存储数据的？</p>
<p>A：InnoDB 的数据是按「数据页」为单位来读写的，默认数据页大小为 16 KB。每个数据页之间通过双向链表的形式组织起来，物理上不连续，但是逻辑上连续。</p>
<p>数据页内包含用户记录，每个记录之间用单向链表的方式组织起来，为了加快在数据页内高效查询记录，设计了一个页目录，页目录存储各个槽（分组），且主键值是有序的，于是可以通过二分查找法的方式进行检索从而提高效率。</p>
<p>为了高效查询记录所在的数据页，InnoDB 采用 b+ 树作为索引，每个节点都是一个数据页。</p>
<p>如果叶子节点存储的是实际数据的就是聚簇索引，一个表只能有一个聚簇索引；如果叶子节点存储的不是实际数据，而是主键值则就是二级索引，一个表中可以有多个二级索引。</p>
<p>在使用二级索引进行查找数据时，如果查询的数据能在二级索引找到，那么就是「索引覆盖」操作，如果查询的数据不在二级索引里，就需要先在二级索引找到主键值，需要去聚簇索引中获得数据行，这个过程就叫作「回表」。</p>
<p>Q：通常B+树有几层？</p>
<p>A：1~3层</p>
<p>Q：为什么说B+树的时间复杂度是稳定的？</p>
<p>A：所有data都存在叶子节点上</p>
<p>Q：最左前缀匹配原则</p>
<p>A：最左前缀匹配原则指的是，在使用联合索引时，<strong>MySQL</strong> 会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，如果查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成，或者在执行过程中遇到范围查询，如 <strong><code>&gt;</code><strong>、</strong><code>&lt;</code><strong>、</strong><code>between</code></strong> 和 <strong><code>以%开头的like查询</code></strong> 等条件，才会停止匹配。</p>
<p>Q：查看表的所有索引</p>
<p>A：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">SHOW</span> <span class="hljs-keyword">INDEX</span> <span class="hljs-keyword">FROM</span> ;<br></code></pre></td></tr></table></figure>

<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>Q：什么是事务</p>
<p>A：<strong>事务是逻辑上的一组操作，要么都执行，要么都不执行</strong></p>
<p>Q：事务的四大特性</p>
<p>A：</p>
<ul>
<li><strong>原子性（Atomicity）</strong>：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。</li>
<li><strong>一致性（Consistency）</strong>：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。</li>
<li><strong>隔离性（Isolation）</strong>：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。</li>
<li><strong>持久性（Durability）</strong>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li>
</ul>
<p>Q：什么是脏读幻读不可重复读</p>
<p>A：</p>
<ul>
<li>脏读：读到其他事务未提交的数据；</li>
<li>不可重复读：前后读取的数据不一致；</li>
<li>幻读：前后读取的记录数量不一致。</li>
</ul>
<p>Q：事务的隔离级别有哪些？</p>
<p>A：</p>
<ul>
<li><strong>读未提交（read uncommitted）</strong>，指一个事务还没提交时，它做的变更就能被其他事务看到；</li>
<li><strong>读提交（read committed）</strong>，指一个事务提交之后，它做的变更才能被其他事务看到；</li>
<li><strong>可重复读（repeatable read）</strong>，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，<strong>MySQL InnoDB 引擎的默认隔离级别</strong>；</li>
<li><strong>串行化（serializable ）</strong>；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；</li>
</ul>
<p>Q：InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？</p>
<p>A：</p>
<ul>
<li>持久性是通过 redo log （重做日志）来保证的；</li>
<li>原子性是通过 undo log（回滚日志） 来保证的；</li>
<li>隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；</li>
<li>一致性则是通过持久性+原子性+隔离性来保证</li>
</ul>
<p>Q：MySQL 的隔离级别是基于锁实现的吗？</p>
<p>A：MySQL 的隔离级别基于锁和 MVCC 机制共同实现的。</p>
<p>Q：Read View 在 MVCC 里如何工作的？</p>
<p>A：Read View格式</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/readview%E7%BB%93%E6%9E%84.drawio.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<ul>
<li>m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的<strong>事务 id 列表</strong>，注意是一个列表，<strong>“活跃事务”指的就是，启动了但还没提交的事务</strong>。</li>
<li>min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 <strong>id 最小的事务</strong>，也就是 m_ids 的最小值。</li>
<li>max_trx_id ：这个并不是 m_ids 的最大值，而是<strong>创建 Read View 时当前数据库中应该给下一个事务的 id 值</strong>，也就是全局事务中最大的事务 id 值 + 1；</li>
<li>creator_trx_id ：指的是<strong>创建该 Read View 的事务的事务 id</strong>。</li>
</ul>
<p>对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列：</p>
<ul>
<li>trx_id，当一个事务对某条聚簇索引记录进行改动时，就会<strong>把该事务的事务 id 记录在 trx_id 隐藏列里</strong>；</li>
<li>roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后<strong>这个隐藏列是个指针，指向每一个旧版本记录</strong>，于是就可以通过它找到修改前的记录。</li>
</ul>
<p>一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：</p>
<ul>
<li><p>如果记录的 trx_id 值小于 Read View 中的 <code>min_trx_id</code> 值，表示这个版本的记录是在创建 Read View <strong>前</strong>已经提交的事务生成的，所以该版本的记录对当前事务<strong>可见</strong>。</p>
</li>
<li><p>如果记录的 trx_id 值大于等于 Read View 中的 <code>max_trx_id</code> 值，表示这个版本的记录是在创建 Read View <strong>后</strong>才启动的事务生成的，所以该版本的记录对当前事务<strong>不可见</strong>。</p>
</li>
<li><p>如果记录的 trx_id 值在 Read View 的</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">min_trx_id</span><br></code></pre></td></tr></table></figure>

<p>和</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">max_trx_id</span><br></code></pre></td></tr></table></figure>

<p>之间，需要判断 trx_id 是否在 m_ids 列表中：</p>
<ul>
<li>如果记录的 trx_id <strong>在</strong> <code>m_ids</code> 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务<strong>不可见</strong>。</li>
<li>如果记录的 trx_id <strong>不在</strong> <code>m_ids</code>列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务<strong>可见</strong>。</li>
</ul>
</li>
</ul>
<p><strong>这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。</strong></p>
<h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>Q：MySQL有哪些锁？</p>
<p><img src="https://img-blog.csdnimg.cn/1e37f6994ef44714aba03b8046b1ace2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>Q：解释下什么是死锁?</p>
<p>A：两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。</p>
<p>Q：为什么会产生死锁</p>
<p>A：两个或两个以上的进程在执行过程中争夺资源</p>
<p>Q：如何避免死锁</p>
<p>A：</p>
<ul>
<li><p><strong>设置事务等待锁的超时时间</strong>。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 <code>innodb_lock_wait_timeout</code> 是用来设置超时时间的，默认值时 50 秒。</p>
<p>当发生超时后，就出现下面这个提示：</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/c296c1889f0101d335699311b4ef20a8.png" srcset="/img/loading.gif" lazyload alt="图片"></p>
<ul>
<li><p><strong>开启主动死锁检测</strong>。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 <code>innodb_deadlock_detect</code> 设置为 on，表示开启这个逻辑，默认就开启。</p>
<p>当检测到死锁后，就会出现下面这个提示：</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/f380ef357d065498d8d54ad07f145e09.png" srcset="/img/loading.gif" lazyload alt="图片"></p>
<p>Q：表级锁和行级锁了解吗？有什么区别？</p>
<p>A：行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），开销大，加锁慢，发生冲突概率更小，并发度更高。</p>
<p><strong>表级锁：</strong> MySQL 中锁定粒度最大的一种锁，是针对非索引字段加的锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。</p>
<p><strong>行级锁：</strong> MySQL 中锁定粒度最小的一种锁，是针对索引字段加的锁，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。</p>
<p>Q：行级锁的使用有什么注意事项？</p>
<p>A：InnoDB 的行锁是针对索引字段加的锁，表级锁是针对非索引字段加的锁。当我们执行 <code>UPDATE</code>、<code>DELETE</code> 语句时，如果 <code>WHERE</code>条件中字段没有命中唯一索引或者索引失效的话，就会导致扫描全表对表中的所有行记录进行加锁。这个在我们日常工作开发中经常会遇到，一定要多多注意！！！</p>
<p>Q：共享锁和排他锁呢？</p>
<p>A：<strong>共享锁（S 锁）</strong> ：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。</p>
<p><strong>排他锁（X 锁）</strong> ：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。</p>
<p>Q：非唯一索引和唯一索引的范围查询的加锁规则不同之处在于</p>
<p>A：</p>
<ul>
<li>唯一索引在满足一些条件的时候，索引的 next-key lock 退化为间隙锁或者记录锁。</li>
<li>非唯一索引范围查询，索引的 next-key lock 不会退化为间隙锁和记录锁。</li>
</ul>
<h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><p>Q：具体更新一条记录 <code>UPDATE t_user SET name = &#39;xiaolin&#39; WHERE id = 1;</code> 的流程如下:</p>
<p>A：</p>
<ol>
<li>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：<ul>
<li>如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</li>
<li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</li>
</ul>
</li>
<li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：<ul>
<li>如果一样的话就不进行后续更新流程；</li>
<li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</li>
</ul>
</li>
<li>开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。</li>
<li>InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 <strong>WAL 技术</strong>，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。</li>
<li>至此，一条记录更新完了。</li>
<li>在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</li>
<li>事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）：<ul>
<li><strong>prepare 阶段</strong>：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li>
<li><strong>commit 阶段</strong>：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；</li>
</ul>
</li>
<li>至此，一条更新语句执行完成。</li>
</ol>
<p>Q：日志的三种分类</p>
<p>A：</p>
<ul>
<li><strong>undo log（回滚日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>原子性</strong>，主要<strong>用于事务回滚和 MVCC</strong>。</li>
<li><strong>redo log（重做日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>持久性</strong>，主要<strong>用于掉电等故障恢复</strong>；</li>
<li><strong>binlog （归档日志）</strong>：是 Server 层生成的日志，主要<strong>用于数据备份和主从复制</strong>；</li>
</ul>
<h4 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h4><p>Q：为什么需要undo log</p>
<p>A：</p>
<ul>
<li><strong>实现事务回滚，保障事务的原子性</strong>。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。</li>
<li><strong>实现 MVCC（多版本并发控制）关键因素之一</strong>。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。</li>
</ul>
<h4 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h4><p>Q：redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？</p>
<p>A：</p>
<p>写入 redo log 的方式使用了追加操作， 所以磁盘操作是<strong>顺序写</strong>，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是<strong>随机写</strong>。</p>
<p>磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。</p>
<p>Q：为什么需要 redo log </p>
<p>A：</p>
<ul>
<li><strong>实现事务的持久性，让 MySQL 有 crash-safe 的能力</strong>，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；</li>
<li><strong>将写操作从「随机写」变成了「顺序写」</strong>，提升 MySQL 写入磁盘的性能。</li>
</ul>
<p>Q：产生的 redo log 是直接写入磁盘的吗？</p>
<p>A：不是的，实际上， 执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I/O 操作，而且磁盘的运行速度远慢于内存。</p>
<p>所以，redo log 也有自己的缓存—— <strong>redo log buffer</strong>，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘如下图：</p>
<p>Q：redo log 什么时候刷盘？</p>
<p>A：</p>
<ul>
<li>MySQL 正常关闭时；</li>
<li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li>
<li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li>
<li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘</li>
</ul>
<h4 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h4><p>Q：redo log 和 binlog 有什么区别？</p>
<p>这两个日志有四个区别。</p>
<p><em>1、适用对象不同：</em></p>
<ul>
<li>binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；</li>
<li>redo log 是 Innodb 存储引擎实现的日志；</li>
</ul>
<p><em>2、文件格式不同：</em></p>
<ul>
<li>binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：<ul>
<li>STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；</li>
<li>ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；</li>
<li>MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；</li>
</ul>
</li>
<li>redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；</li>
</ul>
<p><em>3、写入方式不同：</em></p>
<ul>
<li>binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。</li>
<li>redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。</li>
</ul>
<p><em>4、用途不同：</em></p>
<ul>
<li>binlog 用于备份恢复、主从复制；</li>
<li>redo log 用于掉电等故障恢复。</li>
</ul>
<p>Q：binlog 什么时候刷盘？</p>
<p>A：事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。</p>
<p>Q：主从复制是怎么实现？</p>
<p>A：MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。</p>
<p>这个过程一般是<strong>异步</strong>的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" srcset="/img/loading.gif" lazyload alt="MySQL 主从复制过程"></p>
<p>MySQL 集群的主从复制过程梳理成 3 个阶段：</p>
<ul>
<li><strong>写入 Binlog</strong>：主库写 binlog 日志，提交事务，并更新本地存储数据。</li>
<li><strong>同步 Binlog</strong>：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。</li>
<li><strong>回放 Binlog</strong>：回放 binlog，并更新存储引擎中的数据。</li>
</ul>
<p>具体详细过程如下：</p>
<ul>
<li>MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。</li>
<li>从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。</li>
<li>从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。</li>
</ul>
<p>在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" srcset="/img/loading.gif" lazyload alt="MySQL 主从架构"></p>
<p>Q：从库是不是越多越好？</p>
<p>A：不是的。</p>
<p>因为从库数量增加，从库连接上来的 I/O 线程也比较多，<strong>主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽</strong>。</p>
<p>所以在实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构。</p>
<p>Q：binlog 什么时候刷盘？</p>
<p>A：事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。</p>
<p>Q：主从复制的模型</p>
<p>A：</p>
<ul>
<li><strong>同步复制</strong>：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。这种方式在实际项目中，基本上没法用，原因有两个：一是性能很差，因为要复制到所有节点才返回响应；二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。</li>
<li><strong>异步复制</strong>（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。</li>
<li><strong>半同步复制</strong>：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种<strong>半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险</strong>。</li>
</ul>
<h4 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h4><p>Q：两阶段提交的过程是怎样的？</p>
<p>在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，为了保证这两个日志的一致性，MySQL 使用了<strong>内部 XA 事务</strong>（是的，也有外部 XA 事务，跟本文不太相关，我就不介绍了），内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。</p>
<p>当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，<strong>分两阶段来完成 XA 事务的提交</strong>，如下图：</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" srcset="/img/loading.gif" lazyload alt="两阶段提交"></p>
<p>从图中可看出，事务的提交过程有两个阶段，就是<strong>将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog</strong>，具体如下：</p>
<ul>
<li><strong>prepare 阶段</strong>：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；</li>
<li><strong>commit 阶段</strong>：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；</li>
</ul>
<p>Q：为什么需要两阶段提交</p>
<p>A：<strong>MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决</strong>，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。</p>
<p>Q：处于 prepare 阶段的 redo log 加上完整 binlog，重启就提交事务，MySQL 为什么要这么设计?</p>
<p>A：binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。</p>
<p>所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。</p>
<p>Q：两阶段提交有什么问题？</p>
<p>A：</p>
<ul>
<li><strong>磁盘 I/O 次数高</strong>：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。</li>
<li><strong>锁竞争激烈</strong>：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。</li>
</ul>
<p>Q：什么是组提交</p>
<p>A：</p>
<p><strong>MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数</strong>，如果说 10 个事务依次排队刷盘的时间成本是 10，那么将这 10 个事务一次性一起刷盘的时间成本则近似于 1。</p>
<p>引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：</p>
<ul>
<li><strong>flush 阶段</strong>：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；</li>
<li><strong>sync 阶段</strong>：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；</li>
<li><strong>commit 阶段</strong>：各个事务按顺序做 InnoDB commit 操作；</li>
</ul>
<p>上面的<strong>每个阶段都有一个队列</strong>，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。</p>
<p><img src="http://keithlan.github.io/image/mysql_innodb_arch/commit_4.png" srcset="/img/loading.gif" lazyload alt="每个阶段都有一个队列"></p>
<p>对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整个过程，可以看的出来，<strong>锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率</strong>。</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>Q：MySQL 的 NULL 值是怎么存放的</p>
<p>A：行的格式中包含NULL值列表，<strong>NULL 是不会存放在行格式中记录的真实数据部分里的</strong>，NULL值被放在NULL值列表中</p>
<p>Q：MySQL 的 NULL 值会占用空间吗？</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQlIgynyFHL9VBRpbSanADPgV0cUVI9DBn1VSYsbibiamRzWzsRqukRRag/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" srcset="/img/loading.gif" lazyload alt="图片"></p>
<p>A：Null值列表1字节</p>
<p>Q：MySQL 怎么知道 varchar(n) 实际占用数据的大小？</p>
<p>A：MySQL 的 Compact 行格式中会用「变长字段长度列表」存储变长字段实际占用的数据大小。</p>
<p>Q：varchar(n) 和 char(n) 的区别是什么</p>
<p>A：char 是定长的，varchar 是变长的，变长字段实际存储的数据的长度（大小）不固定的。</p>
<p>Q：varchar(n) 中 n 最大取值为多少？</p>
<p>A：前面我创建表的时候，字段是允许为 NULL 的，所以会占用 1 字节来存储 NULL 标识，字段是变长字段且变长字段允许存储的最大字节数大于 255 字节  ，所以会占用 2 字节存储真实数据的占用的字节数，所以最多可以存储 65535- 2 - 1 = 65532 个字节，所以n最大取值为65532字节</p>
<p>当然，我上面这个例子是针对字符集为 ascii 情况，如果采用的是 UTF-8，varchar(n)  最多能存储的数据计算方式就不一样了：</p>
<ul>
<li>在 UTF-8 字符集下，一个字符串最多需要三个字节，varchar(n) 的 n 最大取值就是 65532/3 = 21844。</li>
</ul>
<p><strong>如果有多个字段的话，要保证所有字段的长度 + 变长字段字节数列表所占用的字节数 + NULL值列表所占用的字节数 &lt;= 65535</strong>。</p>
<p>Q：行溢出后，MySQL 是怎么处理的？</p>
<p>A：如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。在一般情况下，InnoDB 的数据都是存放在 「数据页」中。但是当发生行溢出时，溢出的数据会存放到「溢出页」中。</p>
<p>当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。大致如下图所示。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQPxyPYiaDmGYPCWtQcCjILVVBFYcdegBSRGly002A7wRYqZ355MBdM0w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" srcset="/img/loading.gif" lazyload alt="图片"></p>
<h1 id="Linux命令"><a href="#Linux命令" class="headerlink" title="Linux命令"></a>Linux命令</h1><p>Q：如何查看哪个进程正在监听 80 端口？</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">lsof</span> -i:<span class="hljs-number">80</span><br><span class="hljs-attribute">netstat</span> -tunlp | grep <span class="hljs-number">80</span><br></code></pre></td></tr></table></figure>

<p>Q： linux 命令，如何查看主机 CPU 核数？如何查看内存还剩多少？</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">cat <span class="hljs-regexp">/proc/</span>cpuinfo<br>cat <span class="hljs-regexp">/proc/m</span>eminfo<br></code></pre></td></tr></table></figure>

<p>Q：linux查看日志命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">Linux查看日志的命令有多种: <span class="hljs-built_in">tail</span>、<span class="hljs-built_in">cat</span>、<span class="hljs-built_in">tac</span>、<span class="hljs-built_in">head</span>、<span class="hljs-built_in">echo</span><br></code></pre></td></tr></table></figure>


                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%AE%9E%E4%B9%A0/" class="category-chain-item">实习</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%AE%9E%E4%B9%A0/">#实习</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>实习准备</div>
      <div>http://example.com/2022/11/08/guide/Stereotyped Writing/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>huan</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>November 8, 2022</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/11/27/guide/Computer%20Network/" title="计算机网络">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">计算机网络</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/08/16/training/815-816/" title="暑期集训13">
                        <span class="hidden-mobile">暑期集训13</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
